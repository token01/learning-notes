<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/">
  <channel>
    <atom:link href="https://bytecodes.tech/rss.xml" rel="self" type="application/rss+xml"/>
    <title>凤凰涅槃进阶之路</title>
    <link>https://bytecodes.tech/</link>
    <description>开源工具、效率方法、心理学探索的自我提升笔记，记录并输出一切能让自己提升的知识。</description>
    <language>zh-CN</language>
    <pubDate>Fri, 09 Dec 2022 07:52:17 GMT</pubDate>
    <lastBuildDate>Fri, 09 Dec 2022 07:52:17 GMT</lastBuildDate>
    <generator>vuepress-plugin-feed2</generator>
    <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
    <category>区块链</category>
    <item>
      <title>浅谈共识算法|POS算法</title>
      <link>https://bytecodes.tech/blockchain/Technical_discussion/consensus%E2%80%94%E2%80%94algorithm/1.pow.html</link>
      <guid>https://bytecodes.tech/blockchain/Technical_discussion/consensus%E2%80%94%E2%80%94algorithm/1.pow.html</guid>
      <source url="https://bytecodes.tech/rss.xml">浅谈共识算法|POS算法</source>
      <description>凤凰涅槃进阶之路 web3.0 区块链 区块链基础知识</description>
      <category>区块链</category>
      <pubDate>Wed, 07 Dec 2022 13:53:19 GMT</pubDate>
      <content:encoded><![CDATA[<blockquote>
<p>浅谈共识算法|pow算法</p>
</blockquote>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gn80djrtwej30d606tmxc.jpg" alt="f1" loading="lazy"></p>
<h2 id="概述" tabindex="-1"> 概述</h2>
<p>工作量证明(<code>Proof Of Work</code>，简称<code>POW</code>)，简单理解就是一份证明，用来确认你做过一定量的工作。监测工作的整个过程通常是极为低效的，而通过对工作的结果进行认证来证明完成了相应的工作量，则是一种非常高效的方式。比如现实生活中的毕业证、驾驶证等等，也是通过检验结果的方式（通过相关的考试）所取得的证明。</p>
<p>工作量证明系统（或者说协议、函数），是一种应对拒绝服务攻击和其他服务滥用的经济对策。它要求发起者进行一定量的运算，也就意味着需要消耗计算机一定的时间。这个概念由<strong>Cynthia Dwork</strong> 和<strong>Moni Naor</strong> 1993年在学术论文中首次提出。而工作量证明（<code>POW</code>）这个名词，则是在 1999 年 <strong>Markus Jakobsson</strong> 和<strong>Ari Juels</strong>的文章中才被真正提出。</p>
<h2 id="主流pow共识使用的哈希算法" tabindex="-1"> 主流POW共识使用的哈希算法</h2>
<p>实际不同的<code>POW</code>共识的核心就是<strong>不同的哈希算法</strong>，已经有很多<code>Hash</code>函数被设计出来并广泛应用，不过Hash函数一般安全寿命都不长，被认为安全的算法往往没能使用多久就被成功攻击，新的更安全的算法相继被设计出来，而每一个被公认为安全可靠的算法都有及其严格的审计过程。在币圈中我们经常说某某币发明了某种算法，其实主要都是使用那些被认证过的安全算法，或是单独使用，或是排列组合使用。</p>
<h2 id="sha256" tabindex="-1"> SHA256</h2>
<p><code>SHA-2</code>，名称来自于安全散列算法2（英语：<code>Secure Hash Algorithm 2</code>）的缩写，一种密码散列函数算法标准，由美国国家安全局研发，属于<code>SHA</code>算法之一，是<code>SHA-1</code>的后继者。<code>SHA-2</code>下又可再分为六个不同的算法标准。包括了：<code>SHA-224、SHA-256、SHA-384、SHA-512、SHA-512/224、SHA-512/256。</code></p>
<p>具体的算法解释请查看此文：<a href="https://github.com/blockchainGuide" target="_blank" rel="noopener noreferrer">区块链技术栈全景分析</a></p>
<h2 id="scrypt" tabindex="-1"> SCRYPT</h2>
<p><code>Scrypt</code>是内存依赖型的<code>POW</code>算法，莱特币采用此算法。第一个使用<code>Scrypt</code>算法的数字货币是<code>Tenebrix</code>，而后该算法被<strong>莱特币</strong>使用。莱特币创始人在莱特币创世帖中介绍了莱特币采用的共识机制，挖矿算法，发行总量，挖矿难度等相关重要信息。李启威说明了莱特币所使用的挖矿算法为数字货币<code>Tenebrix</code>所使用的<code>Scrypt</code>算法，是一种符合<code>PoW</code>共识机制的算法。<code>Scrypt</code>算法过程中也需要计算哈希值，但是，<code>Scrypt</code>计算过程中需要使用较多的内存资源。</p>
<p>其它使用Scrypt算法的数字货币还有数码币（<code>DigitalCoin</code>）、狗狗币（<code>DogeCoin</code>）、幸运币（<code>LuckyCoin</code>）、世界币（<code>WorldCoin</code>）等。</p>
<p>算法实现：<a href="https://www.imooc.com/article/50372" target="_blank" rel="noopener noreferrer">https://www.imooc.com/article/50372</a></p>
<h2 id="串联算法" tabindex="-1"> 串联算法</h2>
<p>重新排列组合是人类一贯以来最常用的创新发明方法。很快，有人不满足于使用单一<code>Hash</code>函数，2013年7月，夸克币（<code>Quark</code>）发布，首创使用多轮<code>Hash</code>算法，看似高大上，其实很简单，就是对输入数据运算了9次<code>hash</code>函数，前一轮运算结果作为后一轮运算的输入。这9轮Hash共使用6种加密算法，分别为<code>BLAKE, BMW, GROESTL, JH, KECCAK和SKEIN</code>，这些都是公认的安全<code>Hash</code>算法，并且早已存在现成的实现代码。</p>
<p>这种多轮Hash一出现就给人造成直观上很安全很强大的感觉，追捧者无数。现今价格依然坚挺的达世币率先使用11种加密算法（<code>BLAKE, BMW, GROESTL, JH, KECCAK, SKEIN, LUFFA, CUBEHASH, SHAVITE, SIMD, ECHO</code>），美其名曰X11，紧接着X13，X15这一系列就有人开发出来了。</p>
<p>S系列算法实际是一种串联思路，只要其中一种算法被破解，整个算法就被破解了，好比一根链条，环环相扣，只要其中一环断裂，整个链条就一分为二。</p>
<h2 id="并联算法" tabindex="-1"> 并联算法</h2>
<p><code>Heavycoin（HVC）</code>是第一个做了尝试的并联算法，其原理如下：</p>
<ol>
<li>对输入数据首先运行一次<code>HEFTY1</code>（一种<code>Hash</code>算法）运算，得到结果d1</li>
<li>以<code>d1</code>为输入，依次进行<code>SHA256</code>、<code>KECCAK512</code>、<code>GROESTL512</code>、<code>BLAKE512</code>运算，分别获得输出<code>d2</code>,<code>d3</code>,<code>d4</code>和<code>d5</code></li>
<li>分别提取<code>d2-d5</code>前64位，混淆后形成最终的<code>256</code>位Hash结果，作为区块ID。</li>
</ol>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gn950ksww1j31e60fetfh.jpg" alt="image-20210202134353334" loading="lazy"></p>
<p>之所以首先进行一轮<code>HEFTY1</code> 哈希，是因为HEFTY1 运算起来极其困难，其抵御矿机性能远超于<code>SCRYPT</code>。但与<code>SCRYPT</code>一样，安全性没有得到某个官方机构论证，于是加入后面的四种安全性已经得到公认的算法增强安全。</p>
<p>对比串联和并联的方法，<code>Quark、X11，X13</code>等虽使用了多种<code>HASH</code>函数，但这些算法都是简单的将多种<code>HASH</code>函数串联在一起，仔细思考，其实没有提高整体的抗碰撞性，其安全性更是因木桶效应而由其中安全最弱的算法支撑，其中任何一种<code>Hash</code>函数遭遇碰撞性攻击，都会危及货币系统的安全性。</p>
<p><code>HVC</code>从以上每种算法提取<code>64</code>位，经过融合成为最后的结果，实际上是将四种算法并联在一起，其中一种算法被破解只会危及其中<code>64</code>位，四中算法同时被破解才会危及货币系统的安全性。</p>
<h2 id="ethash" tabindex="-1"> ETHASH</h2>
<p>Ethash是以太坊上面使用的POW算法，具体的介绍可以查看此文（<strong>建议关注此公号</strong>）：<a href="https://mp.weixin.qq.com/s?__biz=MzU2MjY5MzcyMQ==&amp;mid=2247484167&amp;idx=1&amp;sn=1cbec62883c0200c7be39e6986cd53e4&amp;scene=19#wechat_redirect" target="_blank" rel="noopener noreferrer">浅谈以太坊源码分析之ETHASH算法</a></p>
<h2 id="pow算法存在的问题" tabindex="-1"> POW算法存在的问题</h2>
<ol>
<li>算力竞争的设计导致了集中化的矿池：尽管PoW的目的是为了保证系统可以去中心化的运行，然而系统运行到现在，却事实上形成中心化程度很高的五大矿池。五大矿池垄断了世界上90%以上的算力，这可能导致大矿池破坏整个网络的行为</li>
<li>算力竞争的设计导致了大量的能源消耗： 另外，PoW系统需要产生大量的能源消耗：比特币挖矿比159个国家消耗的能源还多；目前77.7%的全球比特币网络算力仍在中国境内；受益于内蒙古和四川两地充沛的电力资源，中国拥有世界上最多的比特币矿场；到2019年7月，比特币网络将需要比美国目前的用电量更多的电力；到2020年2月，它将使用和今天全世界一样多的电力</li>
<li>业务处理性能低下：尽管投入了大量的能源支持系统的运行，但这些能源消耗绝大部份是用于工作量证明中的hash运算，处理交易业务的性能则非常低，例如比特币每秒只能进行大约7笔交易；以太坊每秒10-20笔。</li>
</ol>
<h2 id="参考" tabindex="-1"> 参考</h2>
<blockquote>
<p><a href="https://web.xidian.edu.cn/qqpei/files/Blockchain/2Crypto.pdf" target="_blank" rel="noopener noreferrer">https://web.xidian.edu.cn/qqpei/files/Blockchain/2Crypto.pdf</a></p>
</blockquote>
]]></content:encoded>
      <enclosure url="https://tva1.sinaimg.cn/large/008eGmZEgy1gn80djrtwej30d606tmxc.jpg" type="image/jpeg"/>
    </item>
    <item>
      <title>浅谈共识算法_基于协约</title>
      <link>https://bytecodes.tech/blockchain/Technical_discussion/consensus%E2%80%94%E2%80%94algorithm/10.BFT_agreement_as_whole.html</link>
      <guid>https://bytecodes.tech/blockchain/Technical_discussion/consensus%E2%80%94%E2%80%94algorithm/10.BFT_agreement_as_whole.html</guid>
      <source url="https://bytecodes.tech/rss.xml">浅谈共识算法_基于协约</source>
      <description>凤凰涅槃进阶之路 web3.0 区块链 区块链基础知识</description>
      <category>区块链</category>
      <pubDate>Wed, 07 Dec 2022 13:53:19 GMT</pubDate>
      <content:encoded><![CDATA[<h2 id="基于协约" tabindex="-1"> 基于协约</h2>
<h2 id="pbft" tabindex="-1"> PBFT</h2>
<h2 id="chain协议" tabindex="-1"> chain协议</h2>
<h2 id="ring协议" tabindex="-1"> ring协议</h2>
<h2 id="bft-smart协议" tabindex="-1"> BFT-Smart协议</h2>
<blockquote>
<p><a href="https://www.cnblogs.com/Evsward/p/bft-smart.html" target="_blank" rel="noopener noreferrer">https://www.cnblogs.com/Evsward/p/bft-smart.html</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/101270841" target="_blank" rel="noopener noreferrer">https://zhuanlan.zhihu.com/p/101270841</a></p>
</blockquote>
<h2 id="zyzzyva" tabindex="-1"> Zyzzyva</h2>
<blockquote>
<p><a href="http://sosp2007.org/papers/sosp052-kotla.pdf" target="_blank" rel="noopener noreferrer">http://sosp2007.org/papers/sosp052-kotla.pdf</a></p>
<p><a href="https://www.jianshu.com/p/b4674d3f7ebd" target="_blank" rel="noopener noreferrer">https://www.jianshu.com/p/b4674d3f7ebd</a></p>
</blockquote>
]]></content:encoded>
    </item>
    <item>
      <title>浅谈共识算法_消息处理</title>
      <link>https://bytecodes.tech/blockchain/Technical_discussion/consensus%E2%80%94%E2%80%94algorithm/11.Istanbul_consensus_source_analysis.html</link>
      <guid>https://bytecodes.tech/blockchain/Technical_discussion/consensus%E2%80%94%E2%80%94algorithm/11.Istanbul_consensus_source_analysis.html</guid>
      <source url="https://bytecodes.tech/rss.xml">浅谈共识算法_消息处理</source>
      <description>凤凰涅槃进阶之路 web3.0 区块链 区块链基础知识</description>
      <category>区块链</category>
      <pubDate>Wed, 07 Dec 2022 13:53:19 GMT</pubDate>
      <content:encoded><![CDATA[<h2 id="handler-go-处理消息" tabindex="-1"> handler.go （处理消息）</h2>
<h3 id="start" tabindex="-1"> start</h3>
<ol>
<li>startNewRound(common.Big0)</li>
<li>subscribeEvents()</li>
<li>handleEvents()
<ul>
<li>istanbul.RequestEvent{}</li>
<li>istanbul.MessageEvent{}</li>
<li>backlogEvent{}</li>
<li>timeoutEvent{}</li>
<li>istanbul.FinalCommittedEvent{}</li>
</ul>
</li>
</ol>
<h3 id="stop" tabindex="-1"> stop</h3>
<ol>
<li>roundChangeTimer.Stop()</li>
<li>unsubscribeEvents()
<ul>
<li>events.Unsubscribe()timeoutSub.Unsubscribe()</li>
<li>finalCommittedSub.Unsubscribe()</li>
</ul>
</li>
<li>使得handler处于wait状态</li>
</ol>
<h3 id="handlemsg-handletimeoutmsg" tabindex="-1"> handleMsg&amp;handleTimeoutMsg</h3>
<ol>
<li>先进行msg的check</li>
<li>如果是futureMsg，直接存储并returnErr</li>
<li>接下来处理4个msg</li>
</ol>
<h2 id="startnewround" tabindex="-1"> startNewRound</h2>
<ol>
<li>
<p>首先设置roundChange 为false，如果最新的proposer和proposal不存在，直接return</p>
</li>
<li>
<p>第二个步骤有几个if else 需要拆解（TODO）</p>
</li>
<li>
<p>如果roundChange为true，新建一个View，如果为false，sequence加1</p>
</li>
<li>
<p>选出proposer（CalcProposer），根据valset、lastprotser、round进行选择</p>
</li>
<li>
<p>设置状态为接收请求c.setState(StateAcceptRequest)。</p>
<ul>
<li>
<p>发送istanbul.RequestEvent（把proposal扔出去）</p>
</li>
<li>
<p>处理积压消息（Preprepare）</p>
</li>
<li>
<p>发送backlogEvent事件</p>
</li>
<li>
<p>endPreprepare：</p>
</li>
<li>
<p>如果自己是proposer并且和proposal有着相同的sequence，那就广播preprepare消息</p>
</li>
<li>
<p>广播途中将消息转换成payload 并返回</p>
</li>
</ul>
</li>
</ol>
<h2 id="handlepreprepare" tabindex="-1"> handlePreprepare</h2>
<ul>
<li>校验message ，如果是老的prepare消息，要commit 这个proposal,直接会到广播comiit消息</li>
<li>校验消息来自当前的proposer</li>
<li>校验我们接收到的proposal
<ul>
<li>check 坏块</li>
<li>check block body(rehash)</li>
<li>verifyHeader (TODO,重点了解)</li>
</ul>
</li>
<li>校验之后，（TODO，逻辑？）</li>
</ul>
<p>6.如果锁定的proposal和接收到的proposal不一致就sendNextRoundChange，如果一样，就接收prepare消息并设置状态为StatePreprepared并且发送commit消息</p>
<h2 id="handlecommit" tabindex="-1"> handleCommit</h2>
<ol>
<li>checkMessage</li>
<li>verifyCommit</li>
<li>acceptCommit(添加到commits中)</li>
<li>有了足够的commit messages并且不是comiited状态将commit proposal</li>
<li>Commit
<ul>
<li>设置状态为comitted</li>
<li>创建commitSeals</li>
<li>进入最终的commit代码
<ul>
<li>校验proposal是一个有效块</li>
<li>seals写入到extra-data中（writeCommittedSeals 关键代码）</li>
<li>更新block的header</li>
<li>如果proposedBlockHash == commitedBlockHash ,那么就把block 扔到commitCh中去seal并且等待seal结果（这是proposer才会走的通道），直接返回；如果不一样，直接塞入到enqueue中（sb.broadcaster.Enqueue(fetcherID, block)）</li>
</ul>
</li>
</ul>
</li>
</ol>
<h2 id="handleroundchange" tabindex="-1"> handleRoundChange</h2>
<ol>
<li>checkMessage</li>
<li>roundChangeSet 添加消息</li>
<li>只要达到了F+1个roundChange就构成了一个weak proof ,就可以检查此时的round是否比我们的round小，如果小就CatchUp,然后startNewRound（需要2F+1）</li>
</ol>
<h2 id="engine-go" tabindex="-1"> engine.go</h2>
<h3 id="prepare" tabindex="-1"> prepare</h3>
<p>准备header</p>
<ol>
<li>
<p>sb.snapshot</p>
</li>
<li>
<p>从candidates中随机设置coinbase</p>
</li>
<li>
<p>prepareExtra（将快照中的validators添加到extraData的validators中），payload 数据就是编码后的IstanbulExtra，作为extra</p>
<blockquote>
<div data-ext="go"><pre><code>types<span>.</span>IstanbulExtra<span>{</span>
   Validators<span>:</span>    vals<span>,</span>
   Seal<span>:</span>          <span>[</span><span>]</span><span>byte</span><span>{</span><span>}</span><span>,</span>
   CommittedSeal<span>:</span> <span>[</span><span>]</span><span>[</span><span>]</span><span>byte</span><span>{</span><span>}</span><span>,</span>
<span>}</span>
</code></pre><div aria-hidden="true"><div></div><div></div><div></div><div></div><div></div></div></div></blockquote>
</li>
</ol>
<h3 id="finalizeandassemble" tabindex="-1"> FinalizeAndAssemble</h3>
<p>运行交易后状态更改，组装成最终的block</p>
<h3 id="seal" tabindex="-1"> seal</h3>
<p>生成一个新块放入给定通道</p>
<ol>
<li>主块判断是否是validator，子链还必须判断是不是子validator</li>
<li>更新块（updateBlock），proposer用自己的私钥给块签名生成seal，并写入IstanbulExtra的seal中，包括自己的签名的标记和其他人签名的标记，其实就是返回带签名的块</li>
<li>把块丢到共识引擎中，通过事件istanbul.RequestEvent传播，从而进入到handleRequest，开启sendPrepeare，result等待的就是sb.commitCh中的数据</li>
</ol>
]]></content:encoded>
    </item>
    <item>
      <title>浅谈共识算法|POS算法</title>
      <link>https://bytecodes.tech/blockchain/Technical_discussion/consensus%E2%80%94%E2%80%94algorithm/2.POS-2.html</link>
      <guid>https://bytecodes.tech/blockchain/Technical_discussion/consensus%E2%80%94%E2%80%94algorithm/2.POS-2.html</guid>
      <source url="https://bytecodes.tech/rss.xml">浅谈共识算法|POS算法</source>
      <description>凤凰涅槃进阶之路 web3.0 区块链 区块链基础知识</description>
      <category>区块链</category>
      <pubDate>Wed, 07 Dec 2022 13:53:19 GMT</pubDate>
      <content:encoded><![CDATA[<blockquote>
<p>浅谈共识算法|POS算法</p>
<p>配合以下代码进行阅读：<a href="https://github.com/blockchainGuide/" target="_blank" rel="noopener noreferrer">https://github.com/blockchainGuide/</a></p>
<p>写文不易，给个小关注，有什么问题可以指出，便于大家交流学习。</p>
</blockquote>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gn96oqcxsyj30dw08pjs7.jpg" alt="u=2232051863,378698187&amp;fm=26&amp;gp=0" loading="lazy"></p>
<h2 id="为什么会出现pos" tabindex="-1"> 为什么会出现PoS?</h2>
<p>​    在比特币系统中采用了<code>PoW</code>(工作量证明）算法,<code>PoW</code>其实就是由所有的节点相互竞争，提交一个难于计算但是容易验证的计算结果，任何节点都可以验证这个这个结果的正确性，验证通过即算这个节点完成了大量的计算工作。</p>
<p>​    然而<code>PoW</code>机制存在明显的弊端。 一是算力不公平，矿场的竞争力比单个节点大，还有就是随着硬件的发展，特别是量子计算机的出现，可能几秒就破解了<code>Hash</code>。 二是<code>PoW</code>算法太浪费了，比特币网络每秒可完成数百万亿次<code>SHA256</code>计算， 但这些计算除了使恶意攻击者不能轻易地伪装成几百万个节点和打垮比特币网络，并没有更多实际或科学价值。</p>
<p>​    鉴于以上问题，POS<code>股权证明</code>诞生了。</p>
<h2 id="pos股权证明" tabindex="-1"> PoS股权证明</h2>
<p>​    权益证明（ Proof of Stake，PoS） ，最早在 2013 年被提出，最早在 <code>Peercoin</code> 系统中被实现，类似现实生活中的股东机制，拥有股份越多的人越容易获取记账权（ 同时越倾向于维护网络的正常工作） 。</p>
<p>​    典型的过程是通过保证金（ <strong>代币、资产、名声等具备价值属性的物品</strong>） 来对赌一个合法的块成为新的区块，收益为抵押资本的利息和交易服务费。提供证明的保证金（ 例如通过转账货币记录） 越多，则获得记账权的概率就越大。合法记账者可以获得收益。</p>
<p>​    恶意参与者将存在<strong>保证金</strong>被罚没的风险，即损失经济利益。一般的，对于 PoS 来说，需要掌握超过全网 <strong>1/3</strong> 的资源，才有可能左右最终的结果。这个也很容易理解，三个人投票，前两人分别支持一方，这时候，第三方的投票将决定最终结果。</p>
<p>​    在股权证明模式下， 有一个名词叫<strong>币龄</strong>， 每个币每天产生1币龄， 例如，你持有 100 个币， 总共持有了 30 天， 那么， 此时你的币龄就为 3000， 这个时候， 如果你发现了一个<code>PoS</code>区块， 你的币龄就会被清空为 0。 你每被清空 365币龄， 你将会从区块中获得0.05个币的利息（ 可以理解为年利率5%） ， 那么在这个案例中， 利息<code>=3000×5%/365=0.41</code>个币。</p>
<p>​    以现有的比特币运行发展情况来看， 比特币每年的挖矿产量都在不断减半， 我们可以预计， 随着比特币产量的不断降低， 矿工人数也会越来越少， 这样就会<strong>导致整个比特币网络的稳定性出现问题</strong>。 PoS的解决方案是鼓励大家都去打开钱包客户端程序， 因为只有这样才可以发现PoS区块， 才会获得利息， 这也增加了网络的健壮性。还有当矿工数量变少的时候，比特币被51%算力攻击就越容易。</p>
<h2 id="pos-的优缺点" tabindex="-1"> PoS 的优缺点</h2>
<h2 id="优点" tabindex="-1"> 优点</h2>
<ol>
<li>省资源：不需要挖矿，不需要大量耗费电力和能源。</li>
<li>更加去中心化：相对于比特币等PoW类型的加密货币，更加去中心化，相比PoW算法的51%算力攻击，PoS需要购买51%的货币，成本更高，没有攻击意义。</li>
<li>避免通货膨胀：PoS机制的加密货币按一定的年利率新增货币，可以有效避免紧缩出现，保持基本稳定。</li>
</ol>
<h2 id="缺点" tabindex="-1"> 缺点</h2>
<ol>
<li>POS会面临发币的问题，起初只有创世块上有币，意味着只有这个节点可以挖矿，所以让币分散出去才能让网络壮大，所以早期采取的是POW+POS，即第一阶段POW挖矿，第二阶段POS挖矿，后来ERC20合约代币出现后，可以只存在POS的挖矿形式。</li>
<li>开发者作恶：纯<code>PoS</code>机制的加密货币，只能通过<code>IPO</code>的方式发行，这就导致“少数人”（通常是开发者）获得大量成本极低的加密货币，很有可能造成大面积的抛售。</li>
<li>币龄其实就是时间，一旦挖矿者囤积一定的币，很久很久之后发起攻击，这样将很容易拿到记账权。</li>
<li>矿工可以囤积代币从而导致货币流通困难。</li>
<li>POS面临的最严重的一个问题就是无成本利益问题，在PoS系统中做任何事几乎没有成本，比如在PoS系统上挖矿几乎没有成本，这也就意味着分叉非常方便。</li>
</ol>
<h2 id="参考" tabindex="-1"> 参考</h2>
<blockquote>
<p><a href="https://github.com/blockchainGuide" target="_blank" rel="noopener noreferrer">https://github.com/blockchainGuide</a></p>
<p><a href="https://eth.wiki/en/concepts/casper-proof-of-stake-compendium" target="_blank" rel="noopener noreferrer">https://eth.wiki/en/concepts/casper-proof-of-stake-compendium</a></p>
<p><a href="https://eth.wiki/en/concepts/casper-proof-of-stake-compendium" target="_blank" rel="noopener noreferrer">https://eth.wiki/en/concepts/casper-proof-of-stake-compendium</a></p>
<p><a href="https://eth.wiki/en/concepts/proof-of-stake-faqs" target="_blank" rel="noopener noreferrer">https://eth.wiki/en/concepts/proof-of-stake-faqs</a></p>
<p><a href="https://www.cnblogs.com/sueyyyy/articles/9726812.html" target="_blank" rel="noopener noreferrer">https://www.cnblogs.com/sueyyyy/articles/9726812.html</a></p>
</blockquote>
]]></content:encoded>
      <enclosure url="https://tva1.sinaimg.cn/large/008eGmZEgy1gn96oqcxsyj30dw08pjs7.jpg" type="image/jpeg"/>
    </item>
    <item>
      <title>浅谈共识算法_Casper算法</title>
      <link>https://bytecodes.tech/blockchain/Technical_discussion/consensus%E2%80%94%E2%80%94algorithm/3.consensus_algorithm_is_presented.html</link>
      <guid>https://bytecodes.tech/blockchain/Technical_discussion/consensus%E2%80%94%E2%80%94algorithm/3.consensus_algorithm_is_presented.html</guid>
      <source url="https://bytecodes.tech/rss.xml">浅谈共识算法_Casper算法</source>
      <description>凤凰涅槃进阶之路 web3.0 区块链 区块链基础知识</description>
      <category>区块链</category>
      <pubDate>Wed, 07 Dec 2022 13:53:19 GMT</pubDate>
      <content:encoded><![CDATA[<blockquote>
<p>浅谈共识算法|Casper算法</p>
</blockquote>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gn9b4uqwzsj30et08ct8u.jpg" alt="u=2605093610,3912377035&amp;fm=26&amp;gp=0" loading="lazy"></p>
<h2 id="参考" tabindex="-1"> 参考</h2>
<blockquote>
<p><a href="https://github.com/blockchainGuide" target="_blank" rel="noopener noreferrer">https://github.com/blockchainGuide</a></p>
<p><a href="https://eth.wiki/en/concepts/casper-proof-of-stake-compendium" target="_blank" rel="noopener noreferrer">https://eth.wiki/en/concepts/casper-proof-of-stake-compendium</a></p>
<p><a href="https://eth.wiki/en/concepts/casper-proof-of-stake-compendium" target="_blank" rel="noopener noreferrer">https://eth.wiki/en/concepts/casper-proof-of-stake-compendium</a></p>
<p><a href="https://eth.wiki/en/concepts/proof-of-stake-faqs" target="_blank" rel="noopener noreferrer">https://eth.wiki/en/concepts/proof-of-stake-faqs</a></p>
<p><a href="https://blog.csdn.net/yangwei256/article/details/83188458" target="_blank" rel="noopener noreferrer">https://blog.csdn.net/yangwei256/article/details/83188458</a></p>
<p><a href="https://ethfans.org/posts/ethereum-casper-101" target="_blank" rel="noopener noreferrer">https://ethfans.org/posts/ethereum-casper-101</a></p>
</blockquote>
]]></content:encoded>
      <enclosure url="https://tva1.sinaimg.cn/large/008eGmZEgy1gn9b4uqwzsj30et08ct8u.jpg" type="image/jpeg"/>
    </item>
    <item>
      <title>浅谈共识算法_DPOS(委托股权证明)算法</title>
      <link>https://bytecodes.tech/blockchain/Technical_discussion/consensus%E2%80%94%E2%80%94algorithm/4.dpos.html</link>
      <guid>https://bytecodes.tech/blockchain/Technical_discussion/consensus%E2%80%94%E2%80%94algorithm/4.dpos.html</guid>
      <source url="https://bytecodes.tech/rss.xml">浅谈共识算法_DPOS(委托股权证明)算法</source>
      <description>凤凰涅槃进阶之路 web3.0 区块链 区块链基础知识</description>
      <category>区块链</category>
      <pubDate>Wed, 07 Dec 2022 13:53:19 GMT</pubDate>
      <content:encoded><![CDATA[<blockquote>
<p>浅谈共识算法|DPOS(委托股权证明)算法</p>
<p>写文不易，给个小关注，有什么问题可以指出，便于大家交流学习。</p>
</blockquote>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gna2p4ti6pj31c00u0ahv.jpg" alt="src=http___img.pconline.com.cn_images_upload_upc_tx_wallpaper_1207_09_c2_12276725_1341818508711.jpg&amp;refer=http___img.pconline.com" loading="lazy"></p>
<h2 id="dpos详解" tabindex="-1"> DPOS详解</h2>
<p>DPoS共识算法就是将PoS共识算法中的记账者转换为指定节点数组成的小圈子，而不是所有人都可以参与记账，这个圈子可能是21个节点，也有可能是101个节点，只有圈子内的节点才能获得记账权。这将极大地提高系统的吞吐量，因为更少的节点也就意味着网络和节点的可控。</p>
<p>DPOS的股东选举机制：</p>
<ul>
<li>DPoS机制中的股民（节点）根据自己持有的加密货币数量占总量的百分比（占股比例）来投票，不是一人一票；</li>
<li>选举出的股东代表（可信节点）完全对等，可理解为具有同等算力的101个矿池；</li>
<li>股东代表一旦无能、不作为、胡作为（提供的算力不稳定，计算机宕机、或者试图利用手中的权力作恶），将立刻被股民踢出整个系统，然后由其他后备代表顶上去；</li>
<li>决策完公司大事（记完账、出完块）有钱分，根据占股比例。</li>
</ul>
<h2 id="dpos算法分析" tabindex="-1"> DPOS算法分析</h2>
<p>在DPoS共识算法中，区块链的正常运转依赖于见证人(Delegates)，见证人是由全网节点投票产生的，见证人也是记账节点的实际控制人，相当于咱们选课代表，课代表帮我们整理作业</p>
<p>见证人在完成打包交易的同时可以领取区块奖励和交易的手续费，并且可以执行社区投票的提案，所以DPoS共识算法不仅仅是算法，而是一个包含了协作治理关系的共识机制。</p>
<p>DPoS为了尽快确定交易顺序，过滤无效交易，所以规定了在正常情况下，所有记账节点轮流每3秒产生一个区块，轮到了某个记账节点出块时，必须在2秒内提交区块，否则就会错块。</p>
<p>假设一直没有记账节点错过自己顺序，那么他们生产的链条势必是最长的链条，如果记账节点在非指定时间生产区块被认为是无效的，每经过一轮，所有节点轮流出块的顺序就会发生重新洗牌。</p>
<p>下图就是一个理想的轮流记账状态：</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnade58srjj316o05yju3.jpg" alt="image-20210203151915698" loading="lazy"></p>
<p>DPoS算法白皮书还介绍了以下几种不正常的情况：</p>
<p>①：<strong>少数记账节点发起恶意分叉或者发生故障</strong></p>
<p>可以允许最多1/3的节点是恶意或故障，从而导致出现分叉。在这种情形下，少数分支将只能在9秒内生产1个块，而大多数分支，由于数量多一倍，将预期能在9秒内生产2个块。再一次，诚实的2/3的大多数可以比小的那一部分创建一个更长的链条。</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnadefucijj317u076tb7.jpg" alt="image-20210203151934597" loading="lazy"></p>
<p>②：<strong>隔离环境下的重复块生产</strong></p>
<p>少数群体可能尝试创建一个无限数量的分叉，但所有分支都将比主链短，因为少数群体在链的成长上更慢。</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnadihh19bj316a096mxr.jpg" alt="image-20210203152323992" loading="lazy"></p>
<p>③：<strong>网络碎片</strong></p>
<p>网络非常有可能碎片到，没有哪一个链上的区块生产者占到了所有区块生产者中的大多数。在此情景下，最长的那个链将变成最大的一个少数群体。当网络连接恢复正常后，相对较小的那些群体将自然的切换到最长的链，从而将恢复明确的共识。</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnadj14g6vj31600a0tc7.jpg" alt="image-20210203152359294" loading="lazy"></p>
<p>还有一种非常可能的情况是，三个分支中，最大的两个分支一样大。此时，将由相对更小的第三个分支加入网络时来打破僵局。存在奇数个区块生产者，所以僵局一般不会持续很久。后面我们还将介绍区块生产者的清洗，会将生产者随机生成顺序，以确保即使两个分支具有相同数量的生产者，分支也将以不同的长度爆发增长，导致一个分支最终接管另一个分支。</p>
<p>④：<strong>少数群体重复生产</strong></p>
<p>在这种情景下，少数群体B在自己可以生产的时间节点，同时创建两条，或多条的区块链。下一个执行的生产者C，将选择B创建的可选链中的任一条。C选中的这条链将成为最长的链，当这发生是，所以如下图所示的B1链条上的结点都会转过来。所以，无论少数做恶结点制造多少的链，他们在下一轮中，肯定不会是最长的那个链。</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnadjozhpyj314y07ggo9.jpg" alt="image-20210203152437439" loading="lazy"></p>
<p>⑤：<strong>最后的不可逆区块</strong></p>
<p>在网络碎片的情况下，多个分叉可能持续较长时间的隔离。长远来看，最长的链将最终受到认可。但观察者需要一种手段来确定某个块是否是在最长链条的一部分（确认共识）。这可以通过2/3 + 1个区块生产者是否对某个块有确认。</p>
<p>下图中，块B被A、C确认了，这意味着2/3 + 1都已经确认了。由此我们可以为不可能存在更长的链了，因为2/3的区块链是诚实。</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnadk4gx1dj314y07amyy.jpg" alt="image-20210203152502221" loading="lazy"></p>
<p>需要注意的是这个规则与比特币的6个区块确认类似。一些聪明的人可以设计一系列事件，其中两个节点可能会在不同的最后不可逆块上结束。这种极端情况需要一个攻击者，精确控制通信延迟，并需要在几分钟内实施不止一次，而是二次攻击。如果发生这种情况，那么最长链条这一长期规则仍然适用。 我们估计这种攻击的可能性足够接近0，经济后果也微不足道，不值得担心。</p>
<p>⑥：<strong>不足法定区块生产者</strong></p>
<p>在一些不太可能的情况下，生产者没有明确达到法定人数，少数人可能继续生产块。在继续生产的区块中，利益相关者可以包含一些改变投票的交易。这些投票会选举一组新的区块生产者，并将区块生产参与度恢复到100%。一旦发生这种情况，少数人链最终会超过其它低于100%参与链。</p>
<p>在这个流程发生时，所有的观察者必须要明白整个网络处于不稳定的状态，直到多于67%参与者出现后才会稳定下来。哪些选择在这种情景下发起交易的，与那些在比特币中接受低于6块就确认交易成功那样，冒着类似的风险。他们必须明白，存在某些情况下，共识最终会以另一个链为准。在实践中，这种情形比在比特币中接受少于3个块就确认更加安全。</p>
<p>⑦：<strong>大多数据区块生产者的腐败</strong></p>
<p>如果大多数区块生产者合谋变得腐败，他们制造无限数量的分支，每一个分支都有多于2/3的大多数的签名。在这样的场景早，最后不可逆转块算法退化为最长链算法。此时最长的，获得了最大的群体认证的，将由少数的诚实节点的加入来确定。这样的情形不会持续很久，因为利益相关者会最终投票替换掉这些区块生产者。</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnadl0aqk8j314k08s44j.jpg" alt="image-20210203152553558" loading="lazy"></p>
<h2 id="dpos要解决的问题" tabindex="-1"> DPOS要解决的问题</h2>
<p>从名称上，我们也可以判断出<code>DPoS</code>与<code>PoS</code>共识是直接关联的。<code>DPoS</code>算法是BM根据当时PoW、PoS的不足而改进的共识算法，它的目的就是为了提高性能，也就是交易确认时间短。</p>
<p>在<code>PoS</code>共识中，人们使用财产证明来“挖矿”，也就是说，这是任何人都可以参与的，只要你持有币，你就可以参与挖矿。但是<code>PoS</code>并没有解决性能问题，在这里我们直接认为提高性能就是提高<code>TPS</code>，如下：</p>
<blockquote>
<p><strong>TPS = transactions / block_time</strong></p>
</blockquote>
<p>TPS表示区块链每秒能确认的交易数， <code>transactions</code> 是由区块大小<code>block_size</code>和平均每笔交易大小决定的，而区块大小受全网网络状态<code>network_bandwidth</code> 限制，也是由记账节点之间物理带宽<code>witness_performance</code>决定的。</p>
<p>记账节点的个数<code>witness_count</code>直接决定了物理带宽的上限，因为记账节点数量越多，则对物理带宽要求越高，对网络的稳定性要求也越高。</p>
<p>要注意的一点是在<code>DPoS</code>中，记账节点不叫做矿工，而是改称为见证人，<code>Witness</code>。所以这个公式变成了下面的样子：</p>
<blockquote>
<p>TPS = (block_size_network_bandwidth witness_performance)/(block_time * witness_count)</p>
</blockquote>
<p>我们可以看到，要提高TPS，可以增大区块大小<code>block_size</code>、提升记账节点网络带宽<code>network_bandwidth</code>、提升记账节点处理性能witness_performance，减小区块时间<code>block_time</code>、减小记账节点数量<code>witness_count</code>。</p>
<p>分子项我们可以看到，它基本受限于物理资源的上限，目前工业水平制造的物理资源的使用上限基本就是整个项的上限了，所以可操作性不大。</p>
<p>而分母项是由共识算法决定的，所以我们从区块时间，以及记账节点数入手，DPoS算法便正是从这两项着手的。</p>
<p>首先改动的便是限制记账节点的数量，也就是见证人的数量。</p>
<p>我们在PoW和PoS中可以看到，成为记账节点是无需门槛的，你可以随时参与挖矿，随时退出。</p>
<p>那这会带来什么问题呢，首先无法确定记账节点的数量，其次无法确定记账节点之间的网络环境，记账节点数越多网络环境越复杂，这些不确定性会增大网络分区的概率，从而导致区块链分叉。</p>
<p>如果我们事先规定好记账节点的数量，接着让全网所有节点可以投票决定哪些节点可以成为记账节点，这样就限制并减小了分母项<code>witness_count</code>，这个过程我们也称作投票选举。</p>
<p>因为记账节点数量不多，那么我们可以在共识算法中可以<strong>规定出块时间</strong>为一个固定值，这个值可以很小，通过轮流出块的方式来进行记账。</p>
<p>以上思路基本就是DPoS的基本设计思路，BM还为DPoS算法确立两个原则：</p>
<ul>
<li>投票选举过程一定要保证最大权益所有者最终能控制全网，因为一旦出了问题，他们的损失最大；</li>
<li>与PoW、PoS一样，所有节点仅承认“最长”链。</li>
</ul>
<p>这两个原则确立了DPoS共识的基本特性，第一条放大了PoS共识使用者就是记账者的优点，第二点则规定了分叉时系统应该表现的行为。</p>
<hr>
<h2 id="参考" tabindex="-1"> 参考</h2>
<blockquote>
<p><a href="https://github.com/blockchainGuide" target="_blank" rel="noopener noreferrer">https://github.com/blockchainGuide</a></p>
<p><a href="https://eth.wiki/en/concepts/casper-proof-of-stake-compendium" target="_blank" rel="noopener noreferrer">https://eth.wiki/en/concepts/casper-proof-of-stake-compendium</a></p>
<p><a href="https://eth.wiki/en/concepts/casper-proof-of-stake-compendium" target="_blank" rel="noopener noreferrer">https://eth.wiki/en/concepts/casper-proof-of-stake-compendium</a></p>
<p><a href="https://eth.wiki/en/concepts/proof-of-stake-faqs" target="_blank" rel="noopener noreferrer">https://eth.wiki/en/concepts/proof-of-stake-faqs</a></p>
</blockquote>
]]></content:encoded>
      <enclosure url="https://tva1.sinaimg.cn/large/008eGmZEgy1gna2p4ti6pj31c00u0ahv.jpg" type="image/jpeg"/>
    </item>
    <item>
      <title>浅谈共识算法_DPOS(委托股权证明)算法</title>
      <link>https://bytecodes.tech/blockchain/Technical_discussion/consensus%E2%80%94%E2%80%94algorithm/5.EOS_DPOS_BFT.html</link>
      <guid>https://bytecodes.tech/blockchain/Technical_discussion/consensus%E2%80%94%E2%80%94algorithm/5.EOS_DPOS_BFT.html</guid>
      <source url="https://bytecodes.tech/rss.xml">浅谈共识算法_DPOS(委托股权证明)算法</source>
      <description>凤凰涅槃进阶之路 web3.0 区块链 区块链基础知识</description>
      <category>区块链</category>
      <pubDate>Wed, 07 Dec 2022 13:53:19 GMT</pubDate>
      <content:encoded><![CDATA[<blockquote>
<p>浅谈共识算法|DPOS(委托股权证明)算法</p>
<p>配合以下代码进行阅读：<a href="https://github.com/blockchainGuide/" target="_blank" rel="noopener noreferrer">https://github.com/blockchainGuide/</a></p>
<p>写文不易，给个小关注，有什么问题可以指出，便于大家交流学习。</p>
</blockquote>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gna2p4ti6pj31c00u0ahv.jpg" alt="src=http___img.pconline.com.cn_images_upload_upc_tx_wallpaper_1207_09_c2_12276725_1341818508711.jpg&amp;refer=http___img.pconline.com" loading="lazy"></p>
<h2 id="dpos详解" tabindex="-1"> DPOS详解</h2>
<p>DPoS共识算法就是将PoS共识算法中的记账者转换为指定节点数组成的小圈子，而不是所有人都可以参与记账，这个圈子可能是21个节点，也有可能是101个节点，只有圈子内的节点才能获得记账权。这将极大地提高系统的吞吐量，因为更少的节点也就意味着网络和节点的可控。</p>
<p>DPOS的股东选举机制：</p>
<ul>
<li>DPoS机制中的股民（节点）根据自己持有的加密货币数量占总量的百分比（占股比例）来投票，不是一人一票；</li>
<li>选举出的股东代表（可信节点）完全对等，可理解为具有同等算力的101个矿池；</li>
<li>股东代表一旦无能、不作为、胡作为（提供的算力不稳定，计算机宕机、或者试图利用手中的权力作恶），将立刻被股民踢出整个系统，然后由其他后备代表顶上去；</li>
<li>决策完公司大事（记完账、出完块）有钱分，根据占股比例。</li>
</ul>
<h2 id="dpos算法分析" tabindex="-1"> DPOS算法分析</h2>
<p>在DPoS共识算法中，区块链的正常运转依赖于见证人(Delegates)，见证人是由全网节点投票产生的，见证人也是记账节点的实际控制人，相当于咱们选课代表，课代表帮我们整理作业</p>
<p>见证人在完成打包交易的同时可以领取区块奖励和交易的手续费，并且可以执行社区投票的提案，所以DPoS共识算法不仅仅是算法，而是一个包含了协作治理关系的共识机制。</p>
<p>DPoS为了尽快确定交易顺序，过滤无效交易，所以规定了在正常情况下，所有记账节点轮流每3秒产生一个区块，轮到了某个记账节点出块时，必须在2秒内提交区块，否则就会错块。</p>
<p>假设一直没有记账节点错过自己顺序，那么他们生产的链条势必是最长的链条，如果记账节点在非指定时间生产区块被认为是无效的，每经过一轮，所有节点轮流出块的顺序就会发生重新洗牌。</p>
<p>下图就是一个理想的轮流记账状态：</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnade58srjj316o05yju3.jpg" alt="image-20210203151915698" loading="lazy"></p>
<p>DPoS算法白皮书还介绍了以下几种不正常的情况：</p>
<p>①：<strong>少数记账节点发起恶意分叉或者发生故障</strong></p>
<p>可以允许最多1/3的节点是恶意或故障，从而导致出现分叉。在这种情形下，少数分支将只能在9秒内生产1个块，而大多数分支，由于数量多一倍，将预期能在9秒内生产2个块。再一次，诚实的2/3的大多数可以比小的那一部分创建一个更长的链条。</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnadefucijj317u076tb7.jpg" alt="image-20210203151934597" loading="lazy"></p>
<p>②：<strong>隔离环境下的重复块生产</strong></p>
<p>少数群体可能尝试创建一个无限数量的分叉，但所有分支都将比主链短，因为少数群体在链的成长上更慢。</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnadihh19bj316a096mxr.jpg" alt="image-20210203152323992" loading="lazy"></p>
<p>③：<strong>网络碎片</strong></p>
<p>网络非常有可能碎片到，没有哪一个链上的区块生产者占到了所有区块生产者中的大多数。在此情景下，最长的那个链将变成最大的一个少数群体。当网络连接恢复正常后，相对较小的那些群体将自然的切换到最长的链，从而将恢复明确的共识。</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnadj14g6vj31600a0tc7.jpg" alt="image-20210203152359294" loading="lazy"></p>
<p>还有一种非常可能的情况是，三个分支中，最大的两个分支一样大。此时，将由相对更小的第三个分支加入网络时来打破僵局。存在奇数个区块生产者，所以僵局一般不会持续很久。后面我们还将介绍区块生产者的清洗，会将生产者随机生成顺序，以确保即使两个分支具有相同数量的生产者，分支也将以不同的长度爆发增长，导致一个分支最终接管另一个分支。</p>
<p>④：<strong>少数群体重复生产</strong></p>
<p>在这种情景下，少数群体B在自己可以生产的时间节点，同时创建两条，或多条的区块链。下一个执行的生产者C，将选择B创建的可选链中的任一条。C选中的这条链将成为最长的链，当这发生是，所以如下图所示的B1链条上的结点都会转过来。所以，无论少数做恶结点制造多少的链，他们在下一轮中，肯定不会是最长的那个链。</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnadjozhpyj314y07ggo9.jpg" alt="image-20210203152437439" loading="lazy"></p>
<p>⑤：<strong>最后的不可逆区块</strong></p>
<p>在网络碎片的情况下，多个分叉可能持续较长时间的隔离。长远来看，最长的链将最终受到认可。但观察者需要一种手段来确定某个块是否是在最长链条的一部分（确认共识）。这可以通过2/3 + 1个区块生产者是否对某个块有确认。</p>
<p>下图中，块B被A、C确认了，这意味着2/3 + 1都已经确认了。由此我们可以为不可能存在更长的链了，因为2/3的区块链是诚实。</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnadk4gx1dj314y07amyy.jpg" alt="image-20210203152502221" loading="lazy"></p>
<p>需要注意的是这个规则与比特币的6个区块确认类似。一些聪明的人可以设计一系列事件，其中两个节点可能会在不同的最后不可逆块上结束。这种极端情况需要一个攻击者，精确控制通信延迟，并需要在几分钟内实施不止一次，而是二次攻击。如果发生这种情况，那么最长链条这一长期规则仍然适用。 我们估计这种攻击的可能性足够接近0，经济后果也微不足道，不值得担心。</p>
<p>⑥：<strong>不足法定区块生产者</strong></p>
<p>在一些不太可能的情况下，生产者没有明确达到法定人数，少数人可能继续生产块。在继续生产的区块中，利益相关者可以包含一些改变投票的交易。这些投票会选举一组新的区块生产者，并将区块生产参与度恢复到100%。一旦发生这种情况，少数人链最终会超过其它低于100%参与链。</p>
<p>在这个流程发生时，所有的观察者必须要明白整个网络处于不稳定的状态，直到多于67%参与者出现后才会稳定下来。哪些选择在这种情景下发起交易的，与那些在比特币中接受低于6块就确认交易成功那样，冒着类似的风险。他们必须明白，存在某些情况下，共识最终会以另一个链为准。在实践中，这种情形比在比特币中接受少于3个块就确认更加安全。</p>
<p>⑦：<strong>大多数据区块生产者的腐败</strong></p>
<p>如果大多数区块生产者合谋变得腐败，他们制造无限数量的分支，每一个分支都有多于2/3的大多数的签名。在这样的场景早，最后不可逆转块算法退化为最长链算法。此时最长的，获得了最大的群体认证的，将由少数的诚实节点的加入来确定。这样的情形不会持续很久，因为利益相关者会最终投票替换掉这些区块生产者。</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnadl0aqk8j314k08s44j.jpg" alt="image-20210203152553558" loading="lazy"></p>
<h2 id="dpos要解决的问题" tabindex="-1"> DPOS要解决的问题</h2>
<p>从名称上，我们也可以判断出<code>DPoS</code>与<code>PoS</code>共识是直接关联的。<code>DPoS</code>算法是BM根据当时PoW、PoS的不足而改进的共识算法，它的目的就是为了提高性能，也就是交易确认时间短。</p>
<p>在<code>PoS</code>共识中，人们使用财产证明来“挖矿”，也就是说，这是任何人都可以参与的，只要你持有币，你就可以参与挖矿。但是<code>PoS</code>并没有解决性能问题，在这里我们直接认为提高性能就是提高<code>TPS</code>，如下：</p>
<blockquote>
<p><strong>TPS = transactions / block_time</strong></p>
</blockquote>
<p>TPS表示区块链每秒能确认的交易数， <code>transactions</code> 是由区块大小<code>block_size</code>和平均每笔交易大小决定的，而区块大小受全网网络状态<code>network_bandwidth</code> 限制，也是由记账节点之间物理带宽<code>witness_performance</code>决定的。</p>
<p>记账节点的个数<code>witness_count</code>直接决定了物理带宽的上限，因为记账节点数量越多，则对物理带宽要求越高，对网络的稳定性要求也越高。</p>
<p>要注意的一点是在<code>DPoS</code>中，记账节点不叫做矿工，而是改称为见证人，<code>Witness</code>。所以这个公式变成了下面的样子：</p>
<blockquote>
<p>TPS = (block_size_network_bandwidth witness_performance)/(block_time * witness_count)</p>
</blockquote>
<p>我们可以看到，要提高TPS，可以增大区块大小<code>block_size</code>、提升记账节点网络带宽<code>network_bandwidth</code>、提升记账节点处理性能witness_performance，减小区块时间<code>block_time</code>、减小记账节点数量<code>witness_count</code>。</p>
<p>分子项我们可以看到，它基本受限于物理资源的上限，目前工业水平制造的物理资源的使用上限基本就是整个项的上限了，所以可操作性不大。</p>
<p>而分母项是由共识算法决定的，所以我们从区块时间，以及记账节点数入手，DPoS算法便正是从这两项着手的。</p>
<p>首先改动的便是限制记账节点的数量，也就是见证人的数量。</p>
<p>我们在PoW和PoS中可以看到，成为记账节点是无需门槛的，你可以随时参与挖矿，随时退出。</p>
<p>那这会带来什么问题呢，首先无法确定记账节点的数量，其次无法确定记账节点之间的网络环境，记账节点数越多网络环境越复杂，这些不确定性会增大网络分区的概率，从而导致区块链分叉。</p>
<p>如果我们事先规定好记账节点的数量，接着让全网所有节点可以投票决定哪些节点可以成为记账节点，这样就限制并减小了分母项<code>witness_count</code>，这个过程我们也称作投票选举。</p>
<p>因为记账节点数量不多，那么我们可以在共识算法中可以<strong>规定出块时间</strong>为一个固定值，这个值可以很小，通过轮流出块的方式来进行记账。</p>
<p>以上思路基本就是DPoS的基本设计思路，BM还为DPoS算法确立两个原则：</p>
<ul>
<li>投票选举过程一定要保证最大权益所有者最终能控制全网，因为一旦出了问题，他们的损失最大；</li>
<li>与PoW、PoS一样，所有节点仅承认“最长”链。</li>
</ul>
<p>这两个原则确立了DPoS共识的基本特性，第一条放大了PoS共识使用者就是记账者的优点，第二点则规定了分叉时系统应该表现的行为。</p>
<hr>
<h2 id="参考" tabindex="-1"> 参考</h2>
<blockquote>
<p><a href="https://github.com/blockchainGuide" target="_blank" rel="noopener noreferrer">https://github.com/blockchainGuide</a></p>
<p><a href="https://eth.wiki/en/concepts/casper-proof-of-stake-compendium" target="_blank" rel="noopener noreferrer">https://eth.wiki/en/concepts/casper-proof-of-stake-compendium</a></p>
<p><a href="https://eth.wiki/en/concepts/casper-proof-of-stake-compendium" target="_blank" rel="noopener noreferrer">https://eth.wiki/en/concepts/casper-proof-of-stake-compendium</a></p>
<p><a href="https://eth.wiki/en/concepts/proof-of-stake-faqs" target="_blank" rel="noopener noreferrer">https://eth.wiki/en/concepts/proof-of-stake-faqs</a></p>
</blockquote>
]]></content:encoded>
      <enclosure url="https://tva1.sinaimg.cn/large/008eGmZEgy1gna2p4ti6pj31c00u0ahv.jpg" type="image/jpeg"/>
    </item>
    <item>
      <title>浅谈共识算法|Paxos算法</title>
      <link>https://bytecodes.tech/blockchain/Technical_discussion/consensus%E2%80%94%E2%80%94algorithm/5.Paxos.html</link>
      <guid>https://bytecodes.tech/blockchain/Technical_discussion/consensus%E2%80%94%E2%80%94algorithm/5.Paxos.html</guid>
      <source url="https://bytecodes.tech/rss.xml">浅谈共识算法|Paxos算法</source>
      <description>凤凰涅槃进阶之路 web3.0 区块链 区块链基础知识</description>
      <category>区块链</category>
      <pubDate>Wed, 07 Dec 2022 13:53:19 GMT</pubDate>
      <content:encoded><![CDATA[<blockquote>
<p>配合以下代码进行阅读：<a href="https://github.com/blockchainGuide/" target="_blank" rel="noopener noreferrer">https://github.com/blockchainGuide/</a></p>
<p>写文不易，给个小关注，有什么问题可以指出，便于大家交流学习。</p>
</blockquote>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnuvfqrojoj312w0m8119.jpg" alt="b9a24d7b935c61ba4555b1ddc8159413" loading="lazy"></p>
<h2 id="paxos是什么" tabindex="-1"> Paxos是什么</h2>
<blockquote>
<p>Paxos算法是基于<strong>消息传递</strong>且具有<strong>高度容错特性</strong>的<strong>一致性算法</strong>，是目前公认的解决<strong>分布式一致性</strong>问题<strong>最有效</strong>的算法之一。</p>
</blockquote>
<p><code>Paxos</code>由<code>Lamport</code>于1998年在《The Part-Time Parliament》论文中首次公开，最初的描述使用希腊的一个小岛<code>Paxos</code>作为比喻，描述了<code>Paxos</code>小岛中通过决议的流程，并以此命名这个算法，但是这个描述理解起来比较有挑战性。后来在2001年，<code>Lamport</code>觉得同行不能理解他的幽默感，于是重新发表了朴实的算法描述版本《Paxos Made Simple》。</p>
<p>自<code>Paxos</code>问世以来就持续垄断了分布式一致性算法，<code>Paxos</code>这个名词几乎等同于分布式一致性。<code>Google</code>的很多大型分布式系统都采用了<code>Paxos</code>算法来解决分布式一致性问题。</p>
<h2 id="paxos相关概念" tabindex="-1"> Paxos相关概念</h2>
<p>Paxos算法运行在允许宕机故障的异步系统中，不要求可靠的消息传递，可容忍消息丢失、延迟、乱序以及重复。它利用大多数 (Majority) 机制保证了2F+1的容错能力，即<strong>2F+1</strong>个节点的系统最多允许<strong>F</strong>个节点同时出现故障。</p>
<p>一个或多个提议进程 (Proposer) 可以发起提案 (Proposal)，Paxos算法使所有提案中的某一个提案，在所有进程中达成一致。系统中的多数派同时认可该提案，即达成了一致。最多只针对一个确定的提案达成一致。</p>
<p>Paxos将系统中的角色分为提议者 (Proposer)，决策者 (Acceptor)，和最终决策学习者 (Learner):</p>
<ul>
<li><strong>Proposer</strong>: 提出提案 (Proposal)。Proposal信息包括提案编号 (Proposal ID) 和提议的值 (Value)。</li>
<li><strong>Acceptor</strong>：参与决策，回应Proposers的提案。收到Proposal后可以接受提案，若Proposal获得多数Acceptors的接受，则称该Proposal被批准。</li>
<li><strong>Learner</strong>：不参与决策，从Proposers/Acceptors学习最新达成一致的提案（Value）。</li>
</ul>
<p>在多副本状态机中，每个副本同时具有Proposer、Acceptor、Learner三种角色。</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnuydua826j31gg0i6q5j.jpg" alt="image-20210221103652296" loading="lazy"></p>
<h2 id="paxos算法流程" tabindex="-1"> paxos算法流程</h2>
<p>Paxos算法通过一个决议分为两个阶段（Learn阶段之前决议已经形成）：</p>
<ol>
<li>第一阶段：Prepare阶段。Proposer向Acceptors发出Prepare请求，Acceptors针对收到的Prepare请求进行Promise承诺。</li>
<li>第二阶段：Accept阶段。Proposer收到多数Acceptors承诺的Promise后，向Acceptors发出Propose请求，Acceptors针对收到的Propose请求进行Accept处理。</li>
<li>第三阶段：Learn阶段。Proposer在收到多数Acceptors的Accept之后，标志着本次Accept成功，决议形成，将形成的决议发送给所有Learners。</li>
</ol>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnuyoi6keij318e0isady.jpg" alt="image-20210221104706981" loading="lazy"></p>
<p>Paxos算法流程中的每条消息描述如下：</p>
<ul>
<li><strong>Prepare</strong>: Proposer生成全局唯一且递增的Proposal ID (可使用时间戳加Server ID)，向所有Acceptors发送Prepare请求，这里无需携带提案内容，只携带Proposal ID即可。</li>
<li><strong>Promise</strong>: Acceptors收到Prepare请求后，做出“两个承诺，一个应答”。</li>
</ul>
<p><strong>两个承诺：</strong></p>
<ol>
<li>
<p>不再接受Proposal ID小于等于（注意：这里是&lt;= ）当前请求的Prepare请求。</p>
</li>
<li>
<p>不再接受Proposal ID小于（注意：这里是&lt; ）当前请求的Propose请求。</p>
</li>
</ol>
<p><strong>一个应答：</strong></p>
<p>不违背以前作出的承诺下，回复已经Accept过的提案中Proposal ID最大的那个提案的Value和Proposal ID，没有则返回空值。</p>
<ul>
<li><strong>Propose</strong>: Proposer 收到多数Acceptors的Promise应答后，从应答中选择Proposal ID最大的提案的Value，作为本次要发起的提案。如果所有应答的提案Value均为空值，则可以自己随意决定提案Value。然后携带当前Proposal ID，向所有Acceptors发送Propose请求。</li>
<li><strong>Accept</strong>: Acceptor收到Propose请求后，在不违背自己之前作出的承诺下，接受并持久化当前Proposal ID和提案Value。</li>
<li><strong>Learn</strong>: Proposer收到多数Acceptors的Accept后，决议形成，将形成的决议发送给所有Learners。</li>
</ul>
<p>伪代码流程如下：</p>
<ol>
<li>获取一个Proposal ID n，为了<strong>保证Proposal ID唯一</strong>，可采用时间戳+Server ID生成；</li>
<li>Proposer向所有Acceptors广播Prepare(n)请求；</li>
<li>Acceptor比较n和minProposal，如果n&gt;minProposal，minProposal=n，并且将 acceptedProposal 和 acceptedValue 返回；</li>
<li>Proposer接收到过半数回复后，如果发现有acceptedValue返回，将所有回复中acceptedProposal最大的acceptedValue作为本次提案的value，否则可以任意决定本次提案的value；</li>
<li>到这里可以进入第二阶段，广播Accept (n,value) 到所有节点；</li>
<li>Acceptor比较n和minProposal，如果n&gt;=minProposal，则acceptedProposal=minProposal=n，acceptedValue=value，本地持久化后，返回；否则，返回minProposal。</li>
<li>提议者接收到过半数请求后，如果发现有返回值result &gt;n，表示有更新的提议，跳转到1；否则value达成一致。</li>
</ol>
<h2 id="案例分析" tabindex="-1"> 案例分析</h2>
<p><strong>案例①：</strong></p>
<p>图中P代表Prepare阶段，A代表Accept阶段。3.1代表Proposal ID为3.1，其中3为时间戳，1为Server ID。X和Y代表提议Value。</p>
<p>实例1中P 3.1达成多数派，其Value(X)被Accept，然后P 4.5学习到Value(X)，并Accept。</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnv264l27aj31ce0l4jy9.jpg" alt="image-20210221124740017" loading="lazy"></p>
<p><strong>案例②：</strong></p>
<p>实例2中P 3.1没有被多数派Accept（只有S3 Accept），但是被P 4.5学习到，P 4.5将自己的Value由Y替换为X，Accept（X）。</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnv283ux5xj31bi0gydkn.jpg" alt="image-20210221124945254" loading="lazy"></p>
<p><strong>案例③：</strong></p>
<p>实例3中P 3.1没有被多数派Accept（只有S1 Accept），同时也没有被P 4.5学习到。由于P 4.5 Propose的所有应答，均未返回Value，则P 4.5可以Accept自己的Value (Y)。后续P 3.1的Accept (X) 会失败，已经Accept的S1，会被覆盖。</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnv28vsafmj318q0fsjw8.jpg" alt="image-20210221125030450" loading="lazy"></p>
<p>Paxos算法可能形成活锁而永远不会结束，如下图实例所示：</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnv29ol30oj319y0fyafm.jpg" alt="image-20210221125102677" loading="lazy"></p>
<p>回顾两个承诺之一，Acceptor不再应答Proposal ID小于等于当前请求的Prepare请求。意味着需要应答Proposal ID大于当前请求的Prepare请求。</p>
<p>两个Proposers交替Prepare成功，而Accept失败，形成活锁（Livelock）。</p>
<h2 id="multi-paxos算法" tabindex="-1"> Multi-Paxos算法</h2>
<p>原始的Paxos算法（Basic Paxos）<strong>只能对一个值形成决议</strong>，决议的形成至少需要两次网络来回，在高并发情况下可能需要更多的网络来回，极端情况下甚至可能形成活锁。如果想连续确定多个值，Basic Paxos搞不定了。因此Basic Paxos几乎只是用来做理论研究，并不直接应用在实际工程中。</p>
<p><strong>实际应用中几乎都需要连续确定多个值，而且希望能有更高的效率。Multi-Paxos正是为解决此问题而提出</strong>。Multi-Paxos基于Basic Paxos做了两点改进：</p>
<ol>
<li>针对每一个要确定的值，运行一次Paxos算法实例（Instance），形成决议。每一个Paxos实例使用唯一的Instance ID标识。</li>
<li>在所有Proposers中选举一个Leader，由Leader唯一地提交Proposal给Acceptors进行表决。这样<strong>没有Proposer竞争</strong>，解决了活锁问题。在系统中仅有一个Leader进行Value提交的情况下，Prepare阶段就可以跳过，从而将两阶段变为一阶段，提高效率。</li>
</ol>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnv2e0hvd4j31bs0i00wn.jpg" alt="image-20210221125526065" loading="lazy"></p>
<p>Multi-Paxos首先需要选举Leader，Leader的确定也是一次决议的形成，所以可执行一次Basic Paxos实例来选举出一个Leader。选出Leader之后只能由Leader提交Proposal，在Leader宕机之后服务临时不可用，需要重新选举Leader继续服务。在系统中仅有一个Leader进行Proposal提交的情况下，Prepare阶段可以跳过。</p>
<p>Multi-Paxos通过改变Prepare阶段的作用范围至后面Leader提交的所有实例，从而使得Leader的连续提交只需要执行一次Prepare阶段，后续只需要执行Accept阶段，将两阶段变为一阶段，提高了效率。为了区分连续提交的多个实例，每个实例使用一个Instance ID标识，Instance ID由Leader本地递增生成即可。</p>
<p>Multi-Paxos允许有多个自认为是Leader的节点并发提交Proposal而不影响其安全性，这样的场景即退化为Basic Paxos。</p>
<h2 id="paxos推导过程" tabindex="-1"> Paxos推导过程</h2>
<h2 id="只有一个acceptor" tabindex="-1"> 只有一个Acceptor</h2>
<p>假设只有一个Acceptor（可以有多个Proposer），只要Acceptor接受它收到的第一个提案，则该提案被选定，该提案里的value就是被选定的value。这样就保证只有一个value会被选定。</p>
<p>但是，如果这个唯一的Acceptor宕机了，那么整个系统就<strong>无法工作</strong>了！</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnv2lac3xej313w0gowge.jpg" alt="image-20210221130224968" loading="lazy"></p>
<h2 id="多个acceptor" tabindex="-1"> 多个Acceptor</h2>
<p>多个<code>Acceptor</code>需要保证在多个<code>Proposer</code>和多个<code>Acceptor</code>的情况下选定一个<code>value</code>。</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnv2q6ctcqj31b80i8415.jpg" alt="image-20210221130706677" loading="lazy"></p>
<p>如果我们希望即使只有一个Proposer提出了一个value，该value也最终被选定。</p>
<p>那么，就得到下面的约束：</p>
<blockquote>
<p>P1：一个Acceptor必须接受它收到的第一个提案。</p>
</blockquote>
<p>但是，这又会引出另一个问题：如果每个Proposer分别提出不同的value，发给不同的Acceptor。根据P1，Acceptor分别接受自己收到的value，就导致不同的value被选定。出现了不一致。如下图：</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnv30tvh7ij31dy0pcju7.jpg" alt="image-20210221131721430" loading="lazy"></p>
<p>刚刚是因为『一个提案只要被一个Acceptor接受，则该提案的value就被选定了』才导致了出现上面不一致的问题。因此，我们需要加一个规定：</p>
<blockquote>
<p>规定：一个提案被选定需要被<strong>半数以上</strong>的Acceptor接受</p>
</blockquote>
<p>这个规定又暗示了：『一个Acceptor必须能够接受不止一个提案！』不然可能导致最终没有value被选定。比如上图的情况。v1、v2、v3都没有被选定，因为它们都只被一个Acceptor的接受。</p>
<p>最开始讲的『<strong>提案=value</strong>』已经不能满足需求了，于是重新设计提案，给每个提案加上一个提案编号，表示提案被提出的顺序。令『<strong>提案=提案编号+value</strong>』。</p>
<p>虽然允许多个提案被选定，但必须保证所有被选定的提案都具有相同的value值。否则又会出现不一致。</p>
<p>于是有了下面的约束：</p>
<blockquote>
<p>P2：如果某个value为v的提案被选定了，那么每个编号更高的被选定提案的value必须也是v。</p>
</blockquote>
<p>一个提案只有被Acceptor接受才可能被选定，因此我们可以把P2约束改写成对Acceptor接受的提案的约束P2a。</p>
<blockquote>
<p>P2a：如果某个value为v的提案被选定了，那么每个编号更高的被Acceptor接受的提案的value必须也是v。</p>
</blockquote>
<p>只要满足了P2a，就能满足P2。</p>
<p>但是，考虑如下的情况：假设总的有5个Acceptor。Proposer2提出[M1,V1]的提案，Acceptor25（半数以上）均接受了该提案，于是对于Acceptor25和Proposer2来讲，它们都认为V1被选定。Acceptor1刚刚从宕机状态恢复过来（之前Acceptor1没有收到过任何提案），此时Proposer1向Acceptor1发送了[M2,V2]的提案（V2≠V1且M2&gt;M1），对于Acceptor1来讲，这是它收到的第一个提案。根据P1（一个Acceptor必须接受它收到的第一个提案。）,Acceptor1必须接受该提案！同时Acceptor1认为V2被选定。这就出现了两个问题：</p>
<ol>
<li>Acceptor1认为V2被选定，Acceptor2~5和Proposer2认为V1被选定。出现了不一致。</li>
<li>V1被选定了，但是编号更高的被Acceptor1接受的提案[M2,V2]的value为V2，且V2≠V1。这就跟P2a（如果某个value为v的提案被选定了，那么每个编号更高的被Acceptor接受的提案的value必须也是v）矛盾了。</li>
</ol>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnv3f3co1cj31gs0pk77y.jpg" alt="image-20210221133102803" loading="lazy"></p>
<p>P2a是对Acceptor接受的提案约束，但其实提案是Proposer提出来的，所有我们可以对Proposer提出的提案进行约束。得到P2b：</p>
<blockquote>
<p>P2b：如果某个value为v的提案被选定了，那么之后任何Proposer提出的编号更高的提案的value必须也是v。</p>
</blockquote>
<p>由P2b可以推出P2a进而推出P2。</p>
<p>那么，如何确保在某个value为v的提案被选定后，Proposer提出的编号更高的提案的value都是v呢？</p>
<p>只要满足P2c即可：</p>
<blockquote>
<p>P2c：对于任意的N和V，如果提案[N, V]被提出，那么存在一个半数以上的Acceptor组成的集合S，满足以下两个条件中的任意一个：</p>
</blockquote>
<ul>
<li>S中每个Acceptor都没有接受过编号小于N的提案。</li>
<li>S中Acceptor接受过的最大编号的提案的value为V。</li>
</ul>
<h2 id="proposer生成提案" tabindex="-1"> Proposer生成提案</h2>
<p>为了满足P2b，这里有个比较重要的思想：Proposer生成提案之前，应该先去**『学习』<strong>已经被选定或者可能被选定的value，然后以该value作为自己提出的提案的value。如果没有value被选定，Proposer才可以自己决定value的值。这样才能达成一致。这个学习的阶段是通过一个</strong>『Prepare请求』**实现的。</p>
<p>于是我们得到了如下的<strong>提案生成算法</strong>：</p>
<ol>
<li>
<p>Proposer选择一个<strong>新的提案编号N</strong>，然后向<strong>某个Acceptor集合</strong>（半数以上）发送请求，要求该集合中的每个Acceptor做出如下响应（response）。
(a) 向Proposer承诺保证<strong>不再接受</strong>任何编号<strong>小于N的提案</strong>。
(b) 如果Acceptor已经接受过提案，那么就向Proposer响应<strong>已经接受过</strong>的编号小于N的<strong>最大编号的提案</strong>。</p>
<p>我们将该请求称为<strong>编号为N</strong>的<strong>Prepare请求</strong>。</p>
</li>
<li>
<p>如果Proposer收到了<strong>半数以上</strong>的Acceptor的<strong>响应</strong>，那么它就可以生成编号为N，Value为V的<strong>提案[N,V]</strong>。这里的V是所有的响应中<strong>编号最大的提案的Value</strong>。如果所有的响应中<strong>都没有提案</strong>，那 么此时V就可以由Proposer<strong>自己选择</strong>。
生成提案后，Proposer将该<strong>提案</strong>发送给<strong>半数以上</strong>的Acceptor集合，并期望这些Acceptor能接受该提案。我们称该请求为<strong>Accept请求</strong>。（注意：此时接受Accept请求的Acceptor集合<strong>不一定</strong>是之前响应Prepare请求的Acceptor集合）</p>
</li>
</ol>
<h2 id="为什么需要-propose-阶段" tabindex="-1"> 为什么需要 Propose 阶段</h2>
<p>因为对 paxos 来说，是假定一个集群中会有多个paxos instance（也就是多个提案）同时存在竞争的（并发冲突）。那么 propose 阶段就是选择出需要进行投票的paxos instance。如果能够保证只有一个paxos instance，那么就无需 propose 阶段了，直接进行accept即可。所以对于multi-paxos中，存在一个leader，可以控制每个时刻只有一个paxos instance在集群中，所以不需要propose阶段，只需要执行accept阶段即可。</p>
<p>这里就相当于一个add 1 的paxos instance，一个 delete key 的paxos instance。只有当整个集群指定的 paxos instance 的顺序是相同的，也就是，也就是每个节点都是先add 1，然后在 delete key，或者先delete key，再add 1，最后的数据才会一致。它本质上解决的就是有多个议案的情况下， 达成一个一致的议案，例如，一群人决定聚餐，有想吃鱼的，想吃火锅的，这样多个决议进行 paxos 提案投票，就会得到一个一致的聚餐结果。如果没有多个决议，只有一个决议，那就不会冲突，直接accept投票即可。</p>
<h3 id="paxos-propose-的意义" tabindex="-1"> Paxos Propose 的意义</h3>
<ol>
<li><strong>Block old proposals</strong></li>
<li><strong>Find out about (possibly) accepted values</strong></li>
</ol>
<h2 id="acceptor接受提案" tabindex="-1"> Acceptor接受提案</h2>
<p>Acceptor<strong>可以忽略任何请求</strong>（包括Prepare请求和Accept请求）而不用担心破坏算法的<strong>安全性</strong>。因此，我们这里要讨论的是什么时候Acceptor可以响应一个请求。</p>
<p>我们对Acceptor接受提案给出如下约束：</p>
<blockquote>
<p>P1a：一个Acceptor只要尚<strong>未响应过</strong>任何<strong>编号大于N</strong>的<strong>Prepare请求</strong>，那么他就可以<strong>接受</strong>这个<strong>编号为N的提案</strong>。</p>
</blockquote>
<p>如果Acceptor收到一个编号为N的Prepare请求，在此之前它已经响应过编号大于N的Prepare请求。根据P1a，该Acceptor不可能接受编号为N的提案。因此，该Acceptor可以忽略编号为N的Prepare请求。当然，也可以回复一个error，让Proposer尽早知道自己的提案不会被接受。</p>
<p>因此，一个Acceptor<strong>只需记住</strong>：1. 已接受的编号最大的提案 2. 已响应的请求的最大编号。</p>
<hr>
<h2 id="参考" tabindex="-1"> 参考</h2>
<blockquote>
<p><a href="https://github.com/blockchainGuide" target="_blank" rel="noopener noreferrer">https://github.com/blockchainGuide</a></p>
<p>公号：区块链技术栈</p>
<p><a href="http://zh.wikipedia.org/zh-cn/Paxos%E7%AE%97%E6%B3%95" target="_blank" rel="noopener noreferrer">http://zh.wikipedia.org/zh-cn/Paxos%E7%AE%97%E6%B3%95</a></p>
<p><a href="https://www.cnblogs.com/linbingdong/p/6253479.html" target="_blank" rel="noopener noreferrer">https://www.cnblogs.com/linbingdong/p/6253479.html</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/31780743" target="_blank" rel="noopener noreferrer">https://zhuanlan.zhihu.com/p/31780743</a></p>
<p><a href="https://www.jianshu.com/go-wild?ac=2&amp;url=https%3A%2F%2Fblog.csdn.net%2Fsparkliang%2Farticle%2Fdetails%2F5740882" target="_blank" rel="noopener noreferrer">https://www.jianshu.com/go-wild?ac=2&amp;url=https%3A%2F%2Fblog.csdn.net%2Fsparkliang%2Farticle%2Fdetails%2F5740882</a></p>
<p><a href="https://www.jianshu.com/go-wild?ac=2&amp;url=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fum%2Fpeople%2Flamport%2Fpubs%2Fpaxos-simple.pdf" target="_blank" rel="noopener noreferrer">https://www.jianshu.com/go-wild?ac=2&amp;url=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fum%2Fpeople%2Flamport%2Fpubs%2Fpaxos-simple.pdf</a></p>
<p><a href="https://www.jianshu.com/go-wild?ac=2&amp;url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FPaxos_%28computer_science%29" target="_blank" rel="noopener noreferrer">https://www.jianshu.com/go-wild?ac=2&amp;url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FPaxos_(computer_science)</a></p>
<p><a href="https://www.jianshu.com/p/06a477a576bf" target="_blank" rel="noopener noreferrer">https://www.jianshu.com/p/06a477a576bf</a></p>
</blockquote>
]]></content:encoded>
      <enclosure url="https://tva1.sinaimg.cn/large/008eGmZEgy1gnuvfqrojoj312w0m8119.jpg" type="image/jpeg"/>
    </item>
    <item>
      <title>浅谈共识算法|Raft算法</title>
      <link>https://bytecodes.tech/blockchain/Technical_discussion/consensus%E2%80%94%E2%80%94algorithm/6.Raft.html</link>
      <guid>https://bytecodes.tech/blockchain/Technical_discussion/consensus%E2%80%94%E2%80%94algorithm/6.Raft.html</guid>
      <source url="https://bytecodes.tech/rss.xml">浅谈共识算法|Raft算法</source>
      <description>凤凰涅槃进阶之路 web3.0 区块链 区块链基础知识</description>
      <category>区块链</category>
      <pubDate>Wed, 07 Dec 2022 13:53:19 GMT</pubDate>
      <content:encoded><![CDATA[<blockquote>
<p>浅谈共识算法|Raft算法</p>
<p>配合以下代码进行阅读：<a href="https://github.com/blockchainGuide/" target="_blank" rel="noopener noreferrer">https://github.com/blockchainGuide/</a></p>
<p>写文不易，给个小关注，有什么问题可以指出，便于大家交流学习。</p>
</blockquote>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnv4oqutq9j311x0lcwgh.jpg" alt="a01214b9197eecac0e30d703597788f0" loading="lazy"></p>
<hr>
<h2 id="raft算法概述" tabindex="-1"> Raft算法概述</h2>
<p>不同于Paxos算法直接从分布式一致性问题出发推导出来，Raft算法则是从多副本状态机的角度提出，用于管理多副本状态机的日志复制。Raft实现了和Paxos相同的功能，它将一致性分解为多个子问题：Leader选举（Leader election）、日志同步（Log replication）、安全性（Safety）、日志压缩（Log compaction）、成员变更（Membership change）等。同时，Raft算法使用了更强的假设来减少了需要考虑的状态，使之变的易于理解和实现。</p>
<h2 id="raft算法角色" tabindex="-1"> Raft算法角色</h2>
<p>Raft将系统中的角色分为领导者（Leader）、跟从者（Follower）和候选人（Candidate）：</p>
<ul>
<li><strong>Leader</strong>：接受客户端请求，并向Follower同步请求日志，当日志同步到大多数节点上后告诉Follower提交日志。</li>
<li><strong>Follower</strong>：接受并持久化Leader同步的日志，在Leader告之日志可以提交之后，提交日志。</li>
<li><strong>Candidate</strong>：Leader选举过程中的临时角色。</li>
</ul>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnv5fibnnwj31bc0jgq4d.jpg" alt="image-20210221144024734" loading="lazy"></p>
<p>Raft要求系统在任意时刻最多只有一个Leader，正常工作期间只有Leader和Followers。</p>
<p>Raft算法角色状态转换如下：</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnv77wcjjrj31fy0i8akh.jpg" alt="image-20210221154232947" loading="lazy"></p>
<p>Follower只响应其他服务器的请求。如果Follower超时没有收到Leader的消息，它会成为一个Candidate并且开始一次Leader选举。收到大多数服务器投票的Candidate会成为新的Leader。Leader在宕机之前会一直保持Leader的状态。</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnv79etskij31c40f4ad7.jpg" alt="image-20210221154400705" loading="lazy"></p>
<p>Raft算法将时间分为一个个的任期（term），每一个term的开始都是Leader选举。在成功选举Leader之后，Leader会在整个term内管理整个集群。如果Leader选举失败，该term就会因为没有Leader而结束。</p>
<h2 id="leader选举" tabindex="-1"> Leader选举</h2>
<p>Raft 使用心跳（heartbeat）触发Leader选举。当服务器启动时，初始化为Follower。Leader向所有Followers周期性发送heartbeat。如果Follower在选举超时时间内没有收到Leader的heartbeat，就会等待一段随机的时间后发起一次Leader选举。</p>
<p>Follower将其当前term加一然后转换为Candidate。它首先给自己投票并且给集群中的其他服务器发送 RequestVote RPC 。结果有以下三种情况：</p>
<ul>
<li>赢得了多数的选票，成功选举为Leader；</li>
<li>收到了Leader的消息，表示有其它服务器已经抢先当选了Leader；</li>
<li>没有服务器赢得多数的选票，Leader选举失败，等待选举时间超时后发起下一次选举。</li>
</ul>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnv7bruxirj30xi0u0jsy.jpg" alt="v2-0471619d1b78ba6d57326d97825d9495_r" loading="lazy"></p>
<p>选举出<code>Leader</code>后，<code>Leader</code>通过定期向所有<code>Followers</code>发送心跳信息维持其统治。若<code>Follower</code>一段时间未收到Leader的心跳则认为<code>Leader</code>可能已经挂了，再次发起<code>Leader</code>选举过程。</p>
<p><code>Raft</code>保证选举出的<code>Leader</code>上一定具有最新的已提交的日志。</p>
<h2 id="日志同步" tabindex="-1"> 日志同步</h2>
<p>Leader选出后，就开始接收客户端的请求。Leader把请求作为日志条目（Log entries）加入到它的日志中，然后并行的向其他服务器发起 AppendEntries RPC （RPC细节参见八、Raft算法总结）复制日志条目。当这条日志被复制到大多数服务器上，Leader将这条日志应用到它的状态机并向客户端返回执行结果。</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnv7dki1f3j31e60p6tfm.jpg" alt="image-20210221154800173" loading="lazy"></p>
<p>某些Followers可能没有成功的复制日志，Leader会无限的重试 AppendEntries RPC直到所有的Followers最终存储了所有的日志条目。</p>
<p>日志由有序编号（log index）的日志条目组成。每个日志条目包含它被创建时的任期号（term），和用于状态机执行的命令。如果一个日志条目被复制到大多数服务器上，就被认为可以提交（commit）了。</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnv7e5yoruj31h00skqm1.jpg" alt="image-20210221154824325" loading="lazy"></p>
<p>Raft日志同步保证如下两点：</p>
<ul>
<li>如果不同日志中的两个条目有着相同的索引和任期号，则它们所存储的命令是相同的。</li>
<li>如果不同日志中的两个条目有着相同的索引和任期号，则它们之前的所有条目都是完全一样的。</li>
</ul>
<p>第一条特性源于Leader在一个term内在给定的一个log index最多创建一条日志条目，同时该条目在日志中的位置也从来不会改变。</p>
<p>第二条特性源于 AppendEntries 的一个简单的一致性检查。当发送一个 AppendEntries RPC 时，Leader会把新日志条目紧接着之前的条目的log index和term都包含在里面。如果Follower没有在它的日志中找到log index和term都相同的日志，它就会拒绝新的日志条目。</p>
<p>一般情况下，Leader和Followers的日志保持一致，因此 AppendEntries 一致性检查通常不会失败。然而，Leader崩溃可能会导致日志不一致：旧的Leader可能没有完全复制完日志中的所有条目。</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnv7ejhdj4j31fu0p64fl.jpg" alt="image-20210221154856229" loading="lazy"></p>
<p>上图阐述了一些Followers可能和新的Leader日志不同的情况。一个Follower可能会丢失掉Leader上的一些条目，也有可能包含一些Leader没有的条目，也有可能两者都会发生。丢失的或者多出来的条目可能会持续多个任期。</p>
<p>Leader通过强制Followers复制它的日志来处理日志的不一致，Followers上的不一致的日志会被Leader的日志覆盖。</p>
<p>Leader为了使Followers的日志同自己的一致，Leader需要找到Followers同它的日志一致的地方，然后覆盖Followers在该位置之后的条目。</p>
<p>Leader会从后往前试，每次AppendEntries失败后尝试前一个日志条目，直到成功找到每个Follower的日志一致位点，然后向后逐条覆盖Followers在该位置之后的条目。</p>
<h2 id="安全性" tabindex="-1"> 安全性</h2>
<p>Raft增加了如下两条限制以保证安全性：</p>
<ul>
<li>拥有最新的已提交的log entry的Follower才有资格成为Leader。</li>
</ul>
<p>这个保证是在RequestVote RPC中做的，Candidate在发送RequestVote RPC时，要带上自己的最后一条日志的term和log index，其他节点收到消息时，如果发现自己的日志比请求中携带的更新，则拒绝投票。日志比较的原则是，如果本地的最后一条log entry的term更大，则term大的更新，如果term一样大，则log index更大的更新。</p>
<ul>
<li>Leader只能推进commit index来提交当前term的已经复制到大多数服务器上的日志，旧term日志的提交要等到提交当前term的日志来间接提交（log index 小于 commit index的日志被间接提交）。</li>
</ul>
<p>之所以要这样，是因为可能会出现已提交的日志又被覆盖的情况：</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnv7fah4fcj318k0kaar3.jpg" alt="image-20210221154938685" loading="lazy"></p>
<p>在阶段a，term为2，S1是Leader，且S1写入日志（term, index）为(2, 2)，并且日志被同步写入了S2；</p>
<p>在阶段b，S1离线，触发一次新的选主，此时S5被选为新的Leader，此时系统term为3，且写入了日志（term, index）为（3， 2）;</p>
<p>S5尚未将日志推送到Followers就离线了，进而触发了一次新的选主，而之前离线的S1经过重新上线后被选中变成Leader，此时系统term为4，此时S1会将自己的日志同步到Followers，按照上图就是将日志（2， 2）同步到了S3，而此时由于该日志已经被同步到了多数节点（S1, S2, S3），因此，此时日志（2，2）可以被提交了。；</p>
<p>在阶段d，S1又下线了，触发一次选主，而S5有可能被选为新的Leader（这是因为S5可以满足作为主的一切条件：1. term = 5 &gt; 4，2. 最新的日志为（3，2），比大多数节点（如S2/S3/S4的日志都新），然后S5会将自己的日志更新到Followers，于是S2、S3中已经被提交的日志（2，2）被截断了。</p>
<p>增加上述限制后，即使日志（2，2）已经被大多数节点（S1、S2、S3）确认了，但是它不能被提交，因为它是来自之前term（2）的日志，直到S1在当前term（4）产生的日志（4， 4）被大多数Followers确认，S1方可提交日志（4，4）这条日志，当然，根据Raft定义，（4，4）之前的所有日志也会被提交。此时即使S1再下线，重新选主时S5不可能成为Leader，因为它没有包含大多数节点已经拥有的日志（4，4）。</p>
<h2 id="日志压缩" tabindex="-1"> 日志压缩</h2>
<p>在实际的系统中，不能让日志无限增长，否则系统重启时需要花很长的时间进行回放，从而影响可用性。Raft采用对整个系统进行snapshot来解决，snapshot之前的日志都可以丢弃。</p>
<p>每个副本独立的对自己的系统状态进行snapshot，并且只能对已经提交的日志记录进行snapshot。</p>
<p>Snapshot中包含以下内容：</p>
<ul>
<li>日志元数据。最后一条已提交的 log entry的 log index和term。这两个值在snapshot之后的第一条log entry的AppendEntries RPC的完整性检查的时候会被用上。</li>
<li>系统当前状态。</li>
</ul>
<p>当Leader要发给某个日志落后太多的Follower的log entry被丢弃，Leader会将snapshot发给Follower。或者当新加进一台机器时，也会发送snapshot给它。发送snapshot使用InstalledSnapshot RPC（RPC细节参见八、Raft算法总结）。</p>
<p>做snapshot既不要做的太频繁，否则消耗磁盘带宽， 也不要做的太不频繁，否则一旦节点重启需要回放大量日志，影响可用性。推荐当日志达到某个固定的大小做一次snapshot。</p>
<p>做一次snapshot可能耗时过长，会影响正常日志同步。可以通过使用copy-on-write技术避免snapshot过程影响正常日志同步。</p>
<h2 id="成员变更" tabindex="-1"> 成员变更</h2>
<p>成员变更是在集群运行过程中副本发生变化，如增加/减少副本数、节点替换等。</p>
<p>成员变更也是一个分布式一致性问题，既所有服务器对新成员达成一致。但是成员变更又有其特殊性，因为在成员变更的一致性达成的过程中，参与投票的进程会发生变化。</p>
<p>如果将成员变更当成一般的一致性问题，直接向Leader发送成员变更请求，Leader复制成员变更日志，达成多数派之后提交，各服务器提交成员变更日志后从旧成员配置（Cold）切换到新成员配置（Cnew）。</p>
<p>因为各个服务器提交成员变更日志的时刻可能不同，造成各个服务器从旧成员配置（Cold）切换到新成员配置（Cnew）的时刻不同。</p>
<p>成员变更不能影响服务的可用性，但是成员变更过程的某一时刻，可能出现在Cold和Cnew中同时存在两个不相交的多数派，进而可能选出两个Leader，形成不同的决议，破坏安全性。</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnv7gvonaej31dq0teae6.jpg" alt="image-20210221155100462" loading="lazy"></p>
<p>由于成员变更的这一特殊性，成员变更不能当成一般的一致性问题去解决。</p>
<p>为了解决这一问题，Raft提出了两阶段的成员变更方法。集群先从旧成员配置Cold切换到一个过渡成员配置，称为共同一致（joint consensus），共同一致是旧成员配置Cold和新成员配置Cnew的组合Cold U Cnew，一旦共同一致Cold U Cnew被提交，系统再切换到新成员配置Cnew。</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnv7h61euxj319s0m2n1e.jpg" alt="image-20210221155126751" loading="lazy"></p>
<p>Raft两阶段成员变更过程如下：</p>
<ol>
<li>Leader收到成员变更请求从Cold切成Cnew；</li>
<li>Leader在本地生成一个新的log entry，其内容是Cold∪Cnew，代表当前时刻新旧成员配置共存，写入本地日志，同时将该log entry复制至Cold∪Cnew中的所有副本。在此之后新的日志同步需要保证得到Cold和Cnew两个多数派的确认；</li>
<li>Follower收到Cold∪Cnew的log entry后更新本地日志，并且此时就以该配置作为自己的成员配置；</li>
<li>如果Cold和Cnew中的两个多数派确认了Cold U Cnew这条日志，Leader就提交这条log entry；</li>
<li>接下来Leader生成一条新的log entry，其内容是新成员配置Cnew，同样将该log entry写入本地日志，同时复制到Follower上；</li>
<li>Follower收到新成员配置Cnew后，将其写入日志，并且从此刻起，就以该配置作为自己的成员配置，并且如果发现自己不在Cnew这个成员配置中会自动退出；</li>
<li>Leader收到Cnew的多数派确认后，表示成员变更成功，后续的日志只要得到Cnew多数派确认即可。Leader给客户端回复成员变更执行成功。</li>
</ol>
<p>异常分析：</p>
<ul>
<li>如果Leader的Cold U Cnew尚未推送到Follower，Leader就挂了，此后选出的新Leader并不包含这条日志，此时新Leader依然使用Cold作为自己的成员配置。</li>
<li>如果Leader的Cold U Cnew推送到大部分的Follower后就挂了，此后选出的新Leader可能是Cold也可能是Cnew中的某个Follower。</li>
<li>如果Leader在推送Cnew配置的过程中挂了，那么同样，新选出来的Leader可能是Cold也可能是Cnew中的某一个，此后客户端继续执行一次改变配置的命令即可。</li>
<li>如果大多数的Follower确认了Cnew这个消息后，那么接下来即使Leader挂了，新选出来的Leader肯定位于Cnew中。</li>
</ul>
<p>两阶段成员变更比较通用且容易理解，但是实现比较复杂，同时两阶段的变更协议也会在一定程度上影响变更过程中的服务可用性，因此我们期望增强成员变更的限制，以简化操作流程。</p>
<p>两阶段成员变更，之所以分为两个阶段，是因为对Cold与Cnew的关系没有做任何假设，为了避免Cold和Cnew各自形成不相交的多数派选出两个Leader，才引入了两阶段方案。</p>
<p>如果增强成员变更的限制，假设Cold与Cnew任意的多数派交集不为空，这两个成员配置就无法各自形成多数派，那么成员变更方案就可能简化为一阶段。</p>
<p>那么如何限制Cold与Cnew，使之任意的多数派交集不为空呢？方法就是每次成员变更只允许增加或删除一个成员。</p>
<p>可从数学上严格证明，只要每次只允许增加或删除一个成员，Cold与Cnew不可能形成两个不相交的多数派。</p>
<p>一阶段成员变更：</p>
<ul>
<li>成员变更限制每次只能增加或删除一个成员（如果要变更多个成员，连续变更多次）。</li>
<li>成员变更由Leader发起，Cnew得到多数派确认后，返回客户端成员变更成功。</li>
<li>一次成员变更成功前不允许开始下一次成员变更，因此新任Leader在开始提供服务前要将自己本地保存的最新成员配置重新投票形成多数派确认。</li>
<li>Leader只要开始同步新成员配置，即可开始使用新的成员配置进行日志同步。</li>
</ul>
<h2 id="raft与multi-paxos的异同" tabindex="-1"> Raft与Multi-Paxos的异同</h2>
<p>Raft与Multi-Paxos都是基于领导者的一致性算法，乍一看有很多地方相同，下面总结一下Raft与Multi-Paxos的异同。</p>
<p>Raft与Multi-Paxos中相似的概念：</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnv7hzg71cj31600iuq60.jpg" alt="image-20210221155202104" loading="lazy"></p>
<p>Raft与Multi-Paxos的不同：</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnv7iacddmj31780e2afb.jpg" alt="image-20210221155231875" loading="lazy"></p>
<h2 id="关于raft的一些面试题" tabindex="-1"> 关于Raft的一些面试题</h2>
<h2 id="raft分为哪几个部分" tabindex="-1"> Raft分为哪几个部分？</h2>
<p><strong>主要是分为leader选举、日志复制、日志压缩、成员变更等</strong>。</p>
<h2 id="raft中任何节点都可以发起选举吗" tabindex="-1"> Raft中任何节点都可以发起选举吗？</h2>
<p>Raft发起选举的情况有如下几种：</p>
<ul>
<li>刚启动时，所有节点都是follower，这个时候发起选举，选出一个leader；</li>
<li>当leader挂掉后，<strong>时钟最先跑完的follower发起重新选举操作</strong>，选出一个新的leader。</li>
<li>成员变更的时候会发起选举操作。</li>
</ul>
<h2 id="raft中选举中给候选人投票的前提" tabindex="-1"> Raft中选举中给候选人投票的前提？</h2>
<p><strong>Raft确保新当选的Leader包含所有已提交（集群中大多数成员中已提交）的日志条目</strong>。这个保证是在RequestVoteRPC阶段做的，candidate在发送RequestVoteRPC时，会带上自己的<strong>last log entry的term_id和index</strong>，follower在接收到RequestVoteRPC消息时，<strong>如果发现自己的日志比RPC中的更新，就拒绝投票</strong>。日志比较的原则是，如果本地的最后一条log entry的term id更大，则更新，如果term id一样大，则日志更多的更大(index更大)。</p>
<h2 id="raft网络分区下的数据一致性怎么解决" tabindex="-1"> Raft网络分区下的数据一致性怎么解决？</h2>
<p>发生了网络分区或者网络通信故障，<strong>使得Leader不能访问大多数Follwer了，那么Leader只能正常更新它能访问的那些Follower，而大多数的Follower因为没有了Leader，他们重新选出一个Leader</strong>，然后这个 Leader来接受客户端的请求，如果客户端要求其添加新的日志，这个新的Leader会通知大多数Follower。<strong>如果这时网络故障修复 了，那么原先的Leader就变成Follower，在失联阶段这个老Leader的任何更新都不能算commit，都回滚，接受新的Leader的新的更新（递减查询匹配日志）</strong>。</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnv7jwqaoqj31fg0s444e.jpg" alt="image-20210221155356395" loading="lazy"></p>
<h2 id="raft数据一致性如何实现" tabindex="-1"> Raft数据一致性如何实现？</h2>
<p><strong>主要是通过日志复制实现数据一致性，leader将请求指令作为一条新的日志条目添加到日志中，然后发起RPC 给所有的follower，进行日志复制，进而同步数据</strong>。</p>
<h2 id="raft的日志有什么特点" tabindex="-1"> Raft的日志有什么特点？</h2>
<p><strong>日志由有序编号（log index）的日志条目组成，每个日志条目包含它被创建时的任期号（term）和用于状态机执行的命令</strong>。</p>
<h2 id="raft里面怎么保证数据被commit-leader宕机了会怎样-之前的没提交的数据会怎样" tabindex="-1"> Raft里面怎么保证数据被commit，leader宕机了会怎样，之前的没提交的数据会怎样？</h2>
<p><strong>leader会通过RPC向follower发出日志复制，等待所有的follower复制完成，这个过程是阻塞的</strong>。</p>
<p><strong>老的leader里面没提交的数据会回滚，然后同步新leader的数据</strong>。</p>
<h2 id="raft日志压缩是怎么实现的-增加或删除节点呢" tabindex="-1"> Raft日志压缩是怎么实现的？增加或删除节点呢？？</h2>
<p>在实际的系统中，<strong>不能让日志无限增长</strong>，否则<strong>系统重启时需要花很长的时间进行回放</strong>，从而影响可用性。<strong>Raft采用对整个系统进行snapshot来解决，snapshot之前的日志都可以丢弃（以前的数据已经落盘了）</strong>。</p>
<p><strong>snapshot里面主要记录的是日志元数据，即最后一条已提交的 log entry的 log index和term</strong>。</p>
<h2 id="参考" tabindex="-1"> 参考</h2>
<blockquote>
<p><a href="https://github.com/blockchainGuide" target="_blank" rel="noopener noreferrer">https://github.com/blockchainGuide</a></p>
<p>公号：区块链技术栈 （推荐）</p>
<p><a href="https://raft.github.io/raft.pdf" target="_blank" rel="noopener noreferrer">https://raft.github.io/raft.pdf</a></p>
<p><a href="http://thesecretlivesofdata.com/raft/" target="_blank" rel="noopener noreferrer">http://thesecretlivesofdata.com/raft/</a> （动画演示 推荐）</p>
<p><a href="https://raft.github.io/" target="_blank" rel="noopener noreferrer">https://raft.github.io/</a> （raft资源）</p>
<p><a href="https://zhuanlan.zhihu.com/p/32052223" target="_blank" rel="noopener noreferrer">https://zhuanlan.zhihu.com/p/32052223</a></p>
<p><a href="https://github.com/goraft/raft" target="_blank" rel="noopener noreferrer">https://github.com/goraft/raft</a> （go语言实现）</p>
<p><a href="https://github.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md" target="_blank" rel="noopener noreferrer">https://github.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md</a>（中文翻译地址）</p>
<p><a href="https://github.com/eliben/raft.git" target="_blank" rel="noopener noreferrer">https://github.com/eliben/raft.git</a></p>
</blockquote>
]]></content:encoded>
      <enclosure url="https://tva1.sinaimg.cn/large/008eGmZEgy1gnv4oqutq9j311x0lcwgh.jpg" type="image/jpeg"/>
    </item>
    <item>
      <title>浅谈共识算法|实用拜占庭容错算法(PBFT)</title>
      <link>https://bytecodes.tech/blockchain/Technical_discussion/consensus%E2%80%94%E2%80%94algorithm/8.PBFT.html</link>
      <guid>https://bytecodes.tech/blockchain/Technical_discussion/consensus%E2%80%94%E2%80%94algorithm/8.PBFT.html</guid>
      <source url="https://bytecodes.tech/rss.xml">浅谈共识算法|实用拜占庭容错算法(PBFT)</source>
      <description>凤凰涅槃进阶之路 web3.0 区块链 区块链基础知识</description>
      <category>区块链</category>
      <pubDate>Wed, 07 Dec 2022 13:53:19 GMT</pubDate>
      <content:encoded><![CDATA[<blockquote>
<p>浅谈共识算法|实用拜占庭容错算法(PBFT)</p>
</blockquote>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnv7uqdgnmj31hc0u0wk5.jpg" alt="816246ba75a183d188bdd3bf9c5eed69" loading="lazy"></p>
<h2 id="拜占庭容错bft" tabindex="-1"> 拜占庭容错BFT</h2>
<p>拜占庭容错是分布式协议的一种属性，如果这种协议可以解决不可信任环境下的分布式一致性问题，那么它就是拜占庭容错。</p>
<p>pbft 算法的提出主要是为了解决拜占庭将军问题。网上关于 pbft 的算法介绍基本上是基于 liskov 在 1999 年发表的论文《 Practical Byzantine Fault Tolerance 》来进行解释的。</p>
<h2 id="raft和pbft的最大容错节点数" tabindex="-1"> raft和pbft的最大容错节点数</h2>
<p>对于raft算法，raft算法只支持容错故障节点，不支持容错作恶节点。假设集群总节点数为n，故障节点为 f ，集群里正常节点只需要比 f 个节点再多一个节点，即 f+1 个节点，正确节点的数量就会比故障节点数量多，那么集群就能达成共识。因此 raft 算法支持的最大容错节点数量是（n-1）/2。</p>
<p>对于 pbft 算法，因为 pbft 算法的除了需要支持容错故障节点之外，还需要支持容错作恶节点。假设集群节点数为 N，有问题的节点为 f。有问题的节点中，可以既是故障节点，也可以是作恶节点，或者只是故障节点或者只是作恶节点。那么会产生以下两种极端情况：</p>
<ol>
<li>第一种情况，f 个有问题节点既是故障节点，又是作恶节点，那么根据小数服从多数的原则，集群里正常节点只需要比f个节点再多一个节点，即 f+1 个节点，确节点的数量就会比故障节点数量多，那么集群就能达成共识。也就是说这种情况支持的最大容错节点数量是 （n-1）/2。</li>
<li>第二种情况，故障节点和作恶节点都是不同的节点。那么就会有 f 个问题节点和 f 个故障节点，当发现节点是问题节点后，会被集群排除在外，剩下 f 个故障节点，那么根据小数服从多数的原则，集群里正常节点只需要比f个节点再多一个节点，即 f+1 个节点，确节点的数量就会比故障节点数量多，那么集群就能达成共识。所以，所有类型的节点数量加起来就是 f+1 个正确节点，f个故障节点和f个问题节点，即 3f+1=n。</li>
</ol>
<p>结合上述两种情况，因此 pbft 算法支持的最大容错节点数量是（n-1）/3。</p>
<h2 id="pbft算法流程" tabindex="-1"> PBFT算法流程</h2>
<p>基本流程如下：</p>
<ol>
<li>客户端发送请求给主节点</li>
<li>主节点广播请求给其它节点，节点执行 pbft 算法的三阶段共识流程。</li>
<li>节点处理完三阶段流程后，返回消息给客户端。</li>
<li>客户端收到来自 f+1 个节点的相同消息后，代表共识已经正确完成。</li>
</ol>
<p>无论是最好的情况还是最坏的情况，如果客户端收到 f+1 个节点的相同消息，那么就代表有足够多的正确节点已全部达成共识并处理完毕了。</p>
<p>PBFT 算法中, 存在一个主节点(primary) 和其他的备份节点 (replica), PBFT 共识机制主要包含两部分: 第一部分是分布式共识达成,在主节点正常工作时, PBFT 通过预准备 (pre-prepare)、准备 (prepare) 和承诺 (commit) 三个步骤完成共识; 第二部分是视图转换 (view-change), 当主节点出现问题不能及时处理数据请求时, 其他备份节点发起视图转换, 转换成功后新的主节点开始工作. 主节点以轮转 (round robin) 的方式交替更换.</p>
<p>PBFT 的分布式共识达成过程如下:</p>
<ol>
<li>请求 (propose)：客户端 (client) 上传请求消息 <em>m</em> 至网络中的节点, 包括主节点和其他备份节点。</li>
<li>预准备 (pre-prepare)：主节点收到客户端上传的请求消息 <em>m</em>, 赋予消息序列号 <em>s</em>, 计算得到预准备消息 (pre-prepare*, H*(<em>m</em>)<em>, s, v</em>)，其中 <em>H</em>(m) 是单向哈希函数, <em>v</em> 代表的是此时的视图 (view),视图一般用于记录主节点的更替, 主节点发生更替时, 视图随之增加 1 。消息发送者节点在发送消息前需利用自身私钥对消息实施数字签名。主节点将预准备消息发送给其他备份节点.</li>
<li>准备 (prepare)：备份节点收到主节点的预准备消息, 验证 <em>H</em>(<em>m</em>) 的合法性。即对于视图 <em>v</em> 和序列号<em>s</em> 来说, 备份节点先前并未收到其他消息。验证通过后, 备份节点计算准备消息 (prepare*, H*(<em>m</em>)<em>, s, v</em>) 并将其在全网广播. 与此同时, 所有节点收集准备消息,如果收集到的合法准备消息数量大于等于 2<em>f</em> + 1(包含自身准备消息) 个, 则将其组成准备凭证 (prepared certificate)</li>
<li>承诺 (commit)：如果在准备阶段中, 节点收集到足够的准备消息并生成了准备凭证, 那么节点将计算承诺消息 (commit*, s, v*) 并广播，将消息 <em>m</em> 放入到本地日志中. 与此同时节点收集网络中的承诺消息,如果收集到的合法承诺消息数量大于等于 2<em>f</em> +1(包含自身承诺消息), 那么将其组成承诺凭证 (committedcertificate), 证明消息 <em>m</em> 完成最终承诺。</li>
<li>答复 (reply)：备份节点和主节点中任意收集到足够承诺消息并组成承诺凭证的节点, 将承诺凭证作为对消息 <em>m</em> 的答复发送给客户端, 客户端确认消息 <em>m</em> 的最终承诺.</li>
</ol>
<p>PBFT的共识过程如下：</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnxgennnu6j31fu0g6aet.jpg" alt="image-20210223143130925" loading="lazy"></p>
<h2 id="checkpoint机制" tabindex="-1"> checkpoint机制</h2>
<p>在 PBFT 中, 存在检查点 (checkpoint) 机制, 由于每个消息都被赋予了一定的序列号, 如消息 <em>m</em> 对应的序列号为 118, 当不少于 2<em>f</em> + 1 个节点组成消息 <em>m</em> 的承诺凭证, 完成消息承诺之后, 序列号 118 成为当前的稳定检查点 (stable checkpoint). 检查点机制被用于实现存储删减, 即当历史日志内容过多时, 节点可以选择清除稳定检查点之前的数据, 减少存储成本. 另外稳定检查点在 PBFT 的视图转换中也起到了关键作用.</p>
<h2 id="viewchange机制" tabindex="-1"> viewChange机制</h2>
<p>当主节点挂了（超时无响应）或者从节点集体认为主节点是问题节点时，就会触发 ViewChange 事件， ViewChange 完成后，视图编号将会加 1 。下图展示 ViewChange 的三个阶段流程：</p>
<p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnxgw54qrsj31a00dw7be.jpg" alt="image-20210223144812547" loading="lazy"></p>
<p>viewchange 会有三个阶段，分别是 <code>view-change</code> ， <code>view-change-ack</code> 和 <code>new-view</code> 阶段。从节点认为主节点有问题时，会向其它节点发送 view-change 消息，当前存活的节点编号最小的节点将成为新的主节点。当新的主节点收到 2f 个其它节点的 view-change 消息，则证明有足够多人的节点认为主节点有问题，于是就会向其它节点广播 New-view 消息。注意：从节点不会发起 new-view 事件。对于主节点，发送 new-view 消息后会继续执行上个视图未处理完的请求，从 pre-prepare 阶段开始。其它节点验证 new-view 消息通过后，就会处理主节点发来的 pre-prepare 消息，这时执行的过程就是前面描述的 pbft 过程。</p>
<p>最后一张图来了解一下PBFT算法：</p>
<hr>
<h2 id="参考" tabindex="-1"> 参考</h2>
<blockquote>
<p><a href="https://github.com/blockchainGuide" target="_blank" rel="noopener noreferrer">https://github.com/blockchainGuide</a></p>
<p><a href="http://pmg.csail.mit.edu/papers/osdi99.pdf" target="_blank" rel="noopener noreferrer">http://pmg.csail.mit.edu/papers/osdi99.pdf</a></p>
<p><a href="https://blog.csdn.net/shangsongwww/article/details/88942215" target="_blank" rel="noopener noreferrer">https://blog.csdn.net/shangsongwww/article/details/88942215</a></p>
<p><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/01/thesis-mcastro.pdf" target="_blank" rel="noopener noreferrer">https://www.microsoft.com/en-us/research/wp-content/uploads/2017/01/thesis-mcastro.pdf</a></p>
<p><a href="https://www.comp.nus.edu.sg/~rahul/allfiles/cs6234-16-pbft.pdf" target="_blank" rel="noopener noreferrer">https://www.comp.nus.edu.sg/~rahul/allfiles/cs6234-16-pbft.pdf</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/35847127" target="_blank" rel="noopener noreferrer">https://zhuanlan.zhihu.com/p/35847127</a></p>
<p><a href="https://www.jianshu.com/p/0bef4fb1662b" target="_blank" rel="noopener noreferrer">https://www.jianshu.com/p/0bef4fb1662b</a></p>
<p><a href="https://learnblockchain.cn/article/781" target="_blank" rel="noopener noreferrer">https://learnblockchain.cn/article/781</a>（为什么需要三阶段消息）</p>
<p><a href="https://lessisbetter.site/2020/03/22/why-pbft-needs-viewchange/%EF%BC%88View" target="_blank" rel="noopener noreferrer">https://lessisbetter.site/2020/03/22/why-pbft-needs-viewchange/（View</a> Change的作用）</p>
</blockquote>
]]></content:encoded>
      <enclosure url="https://tva1.sinaimg.cn/large/008eGmZEgy1gnv7uqdgnmj31hc0u0wk5.jpg" type="image/jpeg"/>
    </item>
  </channel>
</rss>