import{_ as l}from"./_plugin-vue_export-helper.cdc0426e.js";import{o as t,c as n,a,d as o,e,r}from"./app.9fe353dd.js";const c="/assets/DevOps-BD-FLINK-1.a64fa8c5.png",p={},d=e('<h2 id="flink" tabindex="-1"><a class="header-anchor" href="#flink" aria-hidden="true">#</a> Flink</h2><p>大数据计算技术演进：</p><ol><li>Hadoop 承载的 MapReduce</li><li>支持 DAG（有向无环图）框架的计算引擎 Tez 和 Oozie，主要还是批处理任务</li><li>支持 Job 内部的 DAG（有向无环图），以 Spark 为代表</li><li>大数据统一计算引擎，包括流处理、批处理、AI、Machine Learning、图计算等，以 Flink 为代表</li></ol><h2 id="场景" tabindex="-1"><a class="header-anchor" href="#场景" aria-hidden="true">#</a> 场景</h2><ul><li>业务数据处理，聚合业务数据，统计分析</li><li>流量日志，动态数据监控</li><li>交通信号灯数据</li><li>道路上车流量统计（拥堵状况）</li><li>公安视频监控</li><li>服务器运行状态监控</li><li>金融证券公司实时跟踪股市波动，计算风险价值</li><li>数据实时 ETL</li><li>银行或者支付公司涉及金融盗窃的预警</li><li>扩展库：CEP（复杂事件处理）、机器学习、图形处理</li></ul><h2 id="大数据" tabindex="-1"><a class="header-anchor" href="#大数据" aria-hidden="true">#</a> 大数据</h2><h3 id="数据集类型" tabindex="-1"><a class="header-anchor" href="#数据集类型" aria-hidden="true">#</a> 数据集类型</h3><ul><li><p>无穷数据集：无穷的持续集成的数据集合</p><blockquote><p>用户与客户端的实时交互数据<br> 应用实时产生的日志<br> 金融市场的实时交易记录</p></blockquote></li><li><p>有界数据集：有限不会改变的数据集合</p></li></ul><h3 id="数据运算模型" tabindex="-1"><a class="header-anchor" href="#数据运算模型" aria-hidden="true">#</a> 数据运算模型</h3><ul><li>流式：只要数据一直在产生，计算就持续地进行</li><li>批处理：在预先定义的时间内运行计算，当计算完成时释放计算机资源</li></ul><p>Flink 其特点就是处理 <strong>流式数据</strong> ，但是他其实是一个针对 <strong>流数据</strong>（DataStream）和 <strong>批数据</strong>（DataSet）的分布式处理引擎，是一个 <strong>流批统一</strong> 的计算引擎。</p><h2 id="部署" tabindex="-1"><a class="header-anchor" href="#部署" aria-hidden="true">#</a> 部署</h2><ul><li><p>Local</p><blockquote><p>直接在 IDE 中运行 Flink Job 时则会在本地启动一个 mini Flink 集群</p></blockquote></li><li><p>Standalone</p><blockquote><p>在 Flink 目录下执行 bin/start-cluster.sh 脚本则会启动一个 Standalone 模式的集群</p></blockquote></li><li><p>YARN</p><blockquote><p>YARN 是 Hadoop 集群的资源管理系统，它可以在群集上运行各种分布式应用程序，Flink 可与其他应用并行于 YARN 中</p></blockquote></li><li><p>Kubernetes</p></li><li><p>AWS、MapR、Aliyun OSS</p></li></ul><h2 id="结构" tabindex="-1"><a class="header-anchor" href="#结构" aria-hidden="true">#</a> 结构</h2><h3 id="api" tabindex="-1"><a class="header-anchor" href="#api" aria-hidden="true">#</a> API</h3><p>至下而上：</p><ul><li><p>Stateful Stream Processing 最底层提供了有状态流</p><blockquote><p>它将通过 Process Function 嵌入到 DataStream API 中。它允许用户可以自由地处理来自一个或多个流数据的事件，并使用一致性、容错的状态。除此之外，用户可以注册事件时间和处理事件回调，从而使程序可以实现复杂的计算。</p></blockquote></li><li><p>DataStream/DataSet API 是 Flink 提供的核心 API</p><blockquote><p>DataSet 处理有界的数据集，DataStream 处理有界或者无界的数据流。用户可以通过各种方法（map/flatmap/window/keyby/sum/max/min/avg/join 等）将数据进行转换或者计算。</p></blockquote></li><li><p>Table API 表为中心的声明式 DSL</p><blockquote><p>其中表可能会动态变化（在表达流数据时）。Table API 提供了例如 select、project、join、group-by、aggregate 等操作，使用起来却更加简洁（代码量更少）。 你可以在表与 DataStream/DataSet 之间无缝切换，也允许程序将 Table API 与 DataStream 以及 DataSet 混合使用。</p></blockquote></li><li><p>SQL</p><blockquote><p>这一层抽象在语法与表达能力上与 Table API 类似，但是是以 SQL查询表达式的形式表现程序。SQL 抽象与 Table API 交互密切，同时 SQL 查询可以直接在 Table API 定义的表上执行。 Flink 除了 DataStream 和 DataSet API，它还支持 Table/SQL API，Flink 也将通过 SQL API 来构建统一的大数据流批处理引擎，因为在公司中通常会有那种每天定时生成报表的需求（批处理的场景，每晚定时跑一遍昨天的数据生成一个结果报表），但是也是会有流处理的场景（比如采用 Flink 来做实时性要求很高的需求），于是慢慢的整个公司的技术选型就变得越来越多了，这样开发人员也就要面临着学习两套不一样的技术框架，运维人员也需要对两种不一样的框架进行环境搭建和作业部署，平时还要维护作业的稳定性。</p></blockquote></li></ul><h3 id="模拟程序与数据流结构" tabindex="-1"><a class="header-anchor" href="#模拟程序与数据流结构" aria-hidden="true">#</a> 模拟程序与数据流结构</h3>',18),s={href:"https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f/topic/5db69938f6a6211cb96164da",target:"_blank",rel:"noopener noreferrer"},h=a("img",{src:c,alt:"",loading:"lazy"},null,-1),u=e('<ul><li><p>Source：数据输入</p><blockquote><p>Flink 在流处理和批处理上的 source 大概有 4 类：基于本地集合的 source、基于文件的 source、基于网络套接字的 source、自定义的 source。自定义的 source 常见的有 Apache kafka、Amazon Kinesis Streams、RabbitMQ、Twitter Streaming API、Apache NiFi 等，当然你也可以定义自己的 source。</p></blockquote></li><li><p>Transformation：数据转换的各种操作</p><blockquote><p>有 Map/FlatMap/Filter/KeyBy/Reduce/Fold/ Aggregations/Window/WindowAll/Union/Window join/Split/Select/Project 等，操作很多，可以将数据转换计算成你想要的数据。</p></blockquote></li><li><p>Sink：数据输出</p><blockquote><p>Flink 将转换计算后的数据发送的地点，你可能需要存储下来，Flink 常见的 Sink 大概有如下几类：写入文件、打印出来、写入 socket、自定义的 sink 。自定义的 Sink 常见的有 Apache kafka、RabbitMQ、MySQL、ElasticSearch、Apache Cassandra、Hadoop FileSystem 等，同理你也可以定义自己的 sink。</p></blockquote></li></ul><h3 id="事件时间-处理时间语义" tabindex="-1"><a class="header-anchor" href="#事件时间-处理时间语义" aria-hidden="true">#</a> 事件时间&amp;处理时间语义</h3><ul><li>Event time 事件自身时间 Ingestion Time 事件进入flink的时间 Processing Time 事件被处理时的机器事件</li></ul><h3 id="窗口机制" tabindex="-1"><a class="header-anchor" href="#窗口机制" aria-hidden="true">#</a> 窗口机制</h3><p>Flink 支持多种 Window，比如 Time Window、Count Window、Session Window，还支持自定义 Window</p><h3 id="并行执行任务" tabindex="-1"><a class="header-anchor" href="#并行执行任务" aria-hidden="true">#</a> 并行执行任务</h3><p>stream partitions operator subtasks</p><h3 id="状态存储和容错" tabindex="-1"><a class="header-anchor" href="#状态存储和容错" aria-hidden="true">#</a> 状态存储和容错</h3><p>Flink 是一款有状态的流处理框架，它提供了丰富的状态访问接口，按照数据的划分方式，可以分为 Keyed State 和 Operator State，在 Keyed State 中又提供了多种数据结构：</p><ul><li>ValueState</li><li>MapState</li><li>ListState</li><li>ReducingState</li><li>AggregatingState</li></ul><p>另外状态存储也支持多种方式：</p><ul><li>MemoryStateBackend：存储在内存中</li><li>FsStateBackend：存储在文件中</li><li>RocksDBStateBackend：存储在 RocksDB 中</li></ul><p>Flink 中支持使用 Checkpoint 来提高程序的可靠性，开启了 Checkpoint 之后，Flink 会按照一定的时间间隔对程序的运行状态进行备份，当发生故障时，Flink 会将所有任务的状态恢复至最后一次发生 Checkpoint 中的状态，并从那里开始重新开始执行。</p><p>另外 Flink 还支持根据 Savepoint 从已停止作业的运行状态进行恢复，这种方式需要通过命令进行触发。</p><h3 id="内存管理机制" tabindex="-1"><a class="header-anchor" href="#内存管理机制" aria-hidden="true">#</a> 内存管理机制</h3><p>Flink 在 JVM 中提供了自己的内存管理，使其独立于 Java 的默认垃圾收集器。它通过使用散列、索引、缓存和排序有效地进行内存管理</p><p>// TODO Flink</p>',17);function k(b,S){const i=r("ExternalLinkIcon");return t(),n("div",null,[d,a("p",null,[a("a",s,[h,o(i)])]),u])}const g=l(p,[["render",k],["__file","Flink.html.vue"]]);export{g as default};
