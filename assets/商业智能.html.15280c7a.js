import{_ as o}from"./_plugin-vue_export-helper.cdc0426e.js";import{o as l,c as i,a as e,b as r,d as a,e as n,r as s}from"./app.48f1d0d6.js";const c="/assets/ETL-ELT.c843cb68.png",h={},d=n('<h2 id="bi-business-intelligence-商业智能" tabindex="-1"><a class="header-anchor" href="#bi-business-intelligence-商业智能" aria-hidden="true">#</a> BI (Business Intelligence) 商业智能</h2><h2 id="etl-extract-transform-load" tabindex="-1"><a class="header-anchor" href="#etl-extract-transform-load" aria-hidden="true">#</a> ETL Extract-Transform-Load</h2><p>ETL是将业务系统的数据经过抽取(Extract)、清洗转换(Transform)之后加载(Load)到数据仓库（Data Warehouse）或数据集市（Data Mart）中，成为联机分析处理（On-Line Analytical Processing，OLAP）、数据挖掘（Data Mining）的基础。目的是将企业中的分散、零乱、标准不统一的数据整合到一起，为企业的决策提供分析依据。</p><blockquote><p><strong>抽取</strong> 是将数据从已有的数据源中提取出来，例如通过 JDBC/Binlog 方式获取 MySQL 数据库的增量数据；<strong>转换</strong> 是对原始数据进行处理，例如将用户属性中的手机号替换为匿名的唯一 ID、计算每个用户对商品的平均打分、计算每个商品的购买数量、将 B 表的数据填充到 A 表中形成新的宽表等；<strong>加载</strong> 是将数据写入目的地。</p></blockquote><p><img src="'+c+'" alt="" loading="lazy"></p>',5),_={href:"http://camel.apache.org/",target:"_blank",rel:"noopener noreferrer"},p={href:"http://apatar.com/",target:"_blank",rel:"noopener noreferrer"},f={href:"http://hekad.readthedocs.io",target:"_blank",rel:"noopener noreferrer"},u={href:"https://www.elastic.co/products/logstash",target:"_blank",rel:"noopener noreferrer"},b={href:"http://scriptella.org/",target:"_blank",rel:"noopener noreferrer"},g={href:"http://www.talend.com/",target:"_blank",rel:"noopener noreferrer"},m={href:"https://github.com/pentaho/pentaho-kettle",target:"_blank",rel:"noopener noreferrer"},w={href:"https://www.informatica.com/",target:"_blank",rel:"noopener noreferrer"},k={href:"https://www.ibm.com/products/infosphere-datastage",target:"_blank",rel:"noopener noreferrer"},E=e("h2",{id:"elt",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#elt","aria-hidden":"true"},"#"),r(" ELT")],-1),L=e("p",null,"ELT 和 ETL 相比，ETL 在数据源抽取后首先进行转换，然后将转换的结果写入目的地。ELT 则是在抽取后将结果先写入目的地，然后由下游应用利用数据库的聚合分析能力或者外部计算框架，例如 Spark 来完成转换的步骤。最大的区别是“重抽取和加载，轻转换”，从而可以用更简单的技术栈、更轻量的方案搭建起一个满足现代企业应用的数据集成平台。AI 应用内在的特点也使得 ELT 特别适合这个场景。",-1),x={href:"https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem",target:"_blank",rel:"noopener noreferrer"},T={href:"https://docs.confluent.io/current/connect/index.html",target:"_blank",rel:"noopener noreferrer"},S={href:"https://github.com/alibaba/DataX",target:"_blank",rel:"noopener noreferrer"},D={href:"https://www.datapipeline.com/",target:"_blank",rel:"noopener noreferrer"},A={id:"案例",tabindex:"-1"},B=e("a",{class:"header-anchor",href:"#案例","aria-hidden":"true"},"#",-1),I={href:"https://mp.weixin.qq.com/s?__biz=MjM5ODI5Njc2MA==&mid=2655830097&idx=1&sn=a637be12d879ab6f43bc35a74cdc70c6",target:"_blank",rel:"noopener noreferrer"},y=n('<p>设计要求在用户输入搜索内容时，要能从商家名称和商品名称两个维度去搜索，搜索出来的结果，按照准确率排序，并按商家所属商品的关联关系，来组合数据结构，同时提供 API 给业务系统调用。</p><ul><li>商家数据库和商品数据库是多台不同的服务器，并且数据量达百万级，如何才能实现跨数据库的数据同步呢？</li><li>商家和商品的数据是有从属关系的，不然就会把肯德基的香辣鸡腿堡挂到麦当劳去，这就尴尬了！</li><li>商家商品数据是经常更新的，比如修改价格、库存、上下架等，那搜索服务可不能搜出一堆过时的数据，如果客户明明搜出来的商品，点进去后却已下架了，那么客户就要吐槽了！如何实现搜索数据与源数据库增删改均实时同步呢？</li></ul><h3 id="架构设计" tabindex="-1"><a class="header-anchor" href="#架构设计" aria-hidden="true">#</a> 架构设计</h3><ul><li>首先，商家数据和商品数据分别存储在 2 个独立的 MySQL8 数据库，为满足商家数据和商品数据的关联，我们需要将两个库中所需要的表实时 ETL 到我们的搜索系统数据库。</li><li>其次，数据从商家、商品数据库 ETL 到搜索系统数据库后，需要实时的组合成为商家关联商品数据结构，并以父子文档的格式，存储到 ES 中。</li><li>最后，商家、商品数据库的增删改操作，需要实时的同步到 ES 中，也就是 ES 中的数据，需要支持实时的增加、删除和修改。</li><li>为此，我们设计了 2 个 Canal 组件，第一个 Canal 实现数据 ETL，把商家、商品数据库的某些表及字段，抽取到搜索服务数据库。</li><li>再利用第二个 Canal，读取搜索服务 MySQL 数据库的 Binlog，实时传输到 Kafka 消息队列，再由 canal adapter 对数据进行关联、父子文档映射等，将处理好的数据存储到 ElasticSearch 中。</li></ul><h2 id="bi商业软件" tabindex="-1"><a class="header-anchor" href="#bi商业软件" aria-hidden="true">#</a> BI商业软件</h2>',5),M={href:"https://www.tableau.com/",target:"_blank",rel:"noopener noreferrer"},C={href:"http://www.powerbi.com.cn/",target:"_blank",rel:"noopener noreferrer"},K={href:"https://powerbi.microsoft.com/",target:"_blank",rel:"noopener noreferrer"},N={href:"http://www.meritdata.com.cn/",target:"_blank",rel:"noopener noreferrer"},j={href:"https://www.dataojo.com/index.html",target:"_blank",rel:"noopener noreferrer"},q={href:"https://www.aliyun.com/product/bigdata/ide",target:"_blank",rel:"noopener noreferrer"};function P(V,v){const t=s("ExternalLinkIcon");return l(),i("div",null,[d,e("ul",null,[e("li",null,[e("a",_,[r("Apache Camel"),a(t)])]),e("li",null,[e("a",p,[r("Apatar"),a(t)])]),e("li",null,[e("a",f,[r("Heka"),a(t)])]),e("li",null,[e("a",u,[r("ElasticSearch"),a(t)])]),e("li",null,[e("a",b,[r("Scriptella"),a(t)])]),e("li",null,[e("a",g,[r("Talend"),a(t)])]),e("li",null,[e("a",m,[r("Kettle"),a(t)])]),e("li",null,[e("a",w,[r("Informatica"),a(t)])]),e("li",null,[e("a",k,[r("DataStage"),a(t)])])]),E,L,e("ul",null,[e("li",null,[e("a",x,[r("Kafka"),a(t)])]),e("li",null,[e("a",T,[r("Kafka Connect"),a(t)])]),e("li",null,[e("a",S,[r("DataX"),a(t)])]),e("li",null,[e("a",D,[r("DataPipeline"),a(t)])])]),e("h2",A,[B,r(),e("a",I,[r("案例"),a(t)])]),y,e("ul",null,[e("li",null,[e("a",M,[r("tableau"),a(t)])]),e("li",null,[e("a",C,[r("powerbi"),a(t)])]),e("li",null,[e("a",K,[r("powerbi microsoft"),a(t)])]),e("li",null,[e("a",N,[r("tempo"),a(t)])]),e("li",null,[e("a",j,[r("dataojo"),a(t)])]),e("li",null,[e("a",q,[r("DataWorks"),a(t)])])])])}const z=o(h,[["render",P],["__file","商业智能.html.vue"]]);export{z as default};
